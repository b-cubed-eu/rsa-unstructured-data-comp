---
title: "Preparation and comparison of structured (SABAP2) and unstructured data for the Western Cape"
author: "Katelyn Faulkner"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
# Load packages
library(tidyverse)    # Data wrangling and visualisation
library(here)         # Relative paths
library(sf)           # Work with spatial data
library(rgbif)        # To request occurrence cubes
library(gcube)        # To create a bespoke cube 
library(iNEXT)        # To calculate sample coverage
library(b3gbi)        # To calculate indicators
library(ggpubr)       # Correlations
library(RColorBrewer) # Colour palette
library(corrplot)     # Correlation plots
```

# Goal

Load, prepare and save structured data for the Western Cape from the “Southern African Bird Atlas Project 2” (SABAP2).

Load and save unstructured data from GBIF.

Make corrections for sample effort and compare the data.

SABAP2 data are collected at a pentad resolution (5min x 5min).

The data are prepared both at a pentad resolution, and at quarter degree grid cell resolution. 9 pentads fit into one quarter degree grid cell (15 min x 15 min)

The period 2015-2023 is of interest. In 2015 there was an improvement in the quality of the data, and as it takes some time for data to flow into GBIF, it is useful to include data up until one full year has passed (e.g., end of 2023 if analysing data in 2025)

# Load data

## Structured data

### Sampling framework

**Western Cape SABAP2 - Southern African Bird Atlas Project 2 - sampling framework for Western Cape** is downloaded as a geoJSON file from https://sabap2.birdmap.africa/coverage/province/westerncape.

Follow the instructions on the website to download the file, then save it as a shapefile and store under *./data/raw*.

We read in the dataset.

```{r}
# Data path and create directory if necessary
data_path <- here::here("data", "raw")
dir.create(data_path, showWarnings = FALSE, recursive = TRUE)
```

```{r}
# Read SABAP2 Western Cape pentad grid (5min x 5 min/ 8.2 km x 8.2 km)
WCSFraw <- read_sf(file.path(data_path, "WesternCape_sampling_framework", "WesternCape_sampling_framework.shp"))

# Explore dataframe
glimpse(WCSFraw)
```

### Occurrence data

Occurrence data was downloaded from GBIF.org.
Unzip and store folder under *./data/raw*.

The following filters were used/considered:
- Occurrence Status IS Present
- Dataset IS 'Southern African Bird Atlas Project 2'
- Year IS '2015-2023'
- Administrative areas (gadm.org) IS 'Western Cape - ZAF.9_1'
- Basis of record IS NOT 'FOSSIL_SPECIMEN' OR 'LIVING_SPECIMEN'
- Issues and Flags NOT = 'Zero coordinate' OR 'Coordinate out of range' OR 'Coordinate invalid' OR 'country coordinate mismatch' OR 'Taxon match higherrank' (i.e., speciesKey IS NOT NULL)
- Location IS 'Including coordinates' (i.e., decimalLatitude IS NOT NULL
AND decimalLongitude IS NOT NULL)

Note that some of the above filters were not relevant (e.g., no fossil specimen records)

Therefore, the SABAP2 dataset was filtered so that only data from the Western Cape between 2015-2023, with speciesKey information was downloaded.

Note these data were not obtained as a cube through rgbif, as some manipulation is required to remove adhoc records that is not possible with the filters available.

**SABAP2 - Southern African Bird Atlas Project 2**: 0031129-250811113504898.zip

GBIF.org (22 August 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.fa9thf

We read in the dataset.

```{r}
# Read SABAP2 data as tab delimited
SABAP2WCraw <- read_delim(file.path(data_path,
                                     "0031129-250811113504898",
                                     "occurrence.txt"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(SABAP2WCraw)
```

## Unstructured data 

### Download cube (qdgc per year)

Retrieved a species occurrence cube using rgbif. 
The occurrence cube is at QDGC scale per year.
To account for sampling bias, the specification recommends including an occurrence count for a higher taxon, typically the family.

The query excluded SABAP2 data

Data for the Western Cape were selected (level1Gid = 'ZAF.9_1')

27 000 m (27km) used as minimum for coordinate uncertainty as smaller than one edge of the grid used (would be 1000 m for a 1 km grid).

Note, personal details (usernname, password and email address) have been removed from script below

```{r, eval = FALSE}
# yearly cube at qdgc resolution
occ_download_sql(user = "", pwd = "", email = "", "SELECT \"year\", GBIF_EQDGCode(2, decimalLatitude, decimalLongitude, COALESCE(coordinateUncertaintyInMeters, 27000)) AS qdgcCode,speciesKey,species, \"order\", family, genus, COUNT(*) AS n,MIN(COALESCE(coordinateUncertaintyInMeters, 27000)) AS minCoordinateUncertaintyInMeters, IF(ISNULL(\"order\"), NULL, SUM(COUNT(*)) OVER (PARTITION BY \"order\")) AS orderCount, IF(ISNULL(family), NULL, SUM(COUNT(*)) OVER (PARTITION BY family)) AS familyCount, IF(ISNULL(genus), NULL, SUM(COUNT(*)) OVER (PARTITION BY genus)) AS genusCount FROM occurrence WHERE class = 'Aves' AND occurrenceStatus = 'PRESENT'AND (coordinateUncertaintyInMeters <= 27000 OR coordinateUncertaintyInMeters IS NULL) AND NOT occurrence.basisofrecord IN ('FOSSIL_SPECIMEN', 'LIVING_SPECIMEN') AND NOT ARRAY_CONTAINS(issue, 'ZERO_COORDINATE') AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_OUT_OF_RANGE') AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_INVALID') AND NOT ARRAY_CONTAINS(issue, 'COUNTRY_COORDINATE_MISMATCH') AND level1Gid = 'ZAF.9_1' AND \"year\" >= 2015 AND \"year\" <= 2023 AND speciesKey IS NOT NULL AND decimalLatitude IS NOT NULL AND decimalLongitude IS NOT NULL AND collectionCode != 'SABAP2' GROUP BY \"year\", qdgcCode, speciesKey, \"order\", family, genus, species ORDER BY \"year\" ASC, qdgcCode ASC, speciesKey ASC")
```

The data are downloaded and stored under *./data/raw*.

**Unstructured bird data Western Cape QGDC cube**: 0002416-251025141854904.zip

GBIF.org (27 October 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.nqf9x5

We read in the dataset.

```{r}
# Read in datacube from CSV
birdcubeWCYearQDGC <- read_delim(file.path(data_path,
                                     "0002416-251025141854904", "0002416-251025141854904.csv"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(birdcubeWCYearQDGC)
```

### Download occurrence data and create cube (pentad per year)

Cube at pentad resolution not available through rgbif. Therefore, retrieved species occurrence data using rgbif, and created a yearly cube at pentad resolution using gcube.

Occurrence data is downloaded from GBIF.org. Unzip and store folders under *./data/raw*.

The query had the same specifications as the cube query, except 8 000 m (8km) was used as minimum for coordinate uncertainty, as smaller than one edge of the grid used (would be 1000 m for a 1 km grid).

Note, personal details (usernname, password and email address) have been removed from script below

```{r}
occ_download(user = "", pwd = "", email = "", pred("taxonKey", 212), 
             pred("occurrenceStatus", "PRESENT"), 
             pred_or(pred_lte("coordinateUncertaintyInMeters", 8000),pred_isnull("coordinateUncertaintyInMeters")), 
             pred("gadm", "ZAF.9_1"), 
             pred_and(pred_gte("year","2015"), pred_lte("year", "2023")), 
             pred_notnull("speciesKey"), 
             pred_notnull("decimalLatitude"), 
             pred_notnull("decimalLongitude"), 
             pred_not(pred_in("collectionCode", "SABAP2")), 
             pred_not(pred_in("basisOfRecord", c("FOSSIL_SPECIMEN", "LIVING_SPECIMEN"))),
             pred_not(pred_in("issue", c("ZERO_COORDINATE", "COORDINATE_OUT_OF_RANGE", "COORDINATE_INVALID", "COUNTRY_COORDINATE_MISMATCH"))))
```

**Unstructured bird data Western Cape**: 0002426-251025141854904.zip

GBIF.org (27 October 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.jxzwn4

We read in the dataset.

```{r}
# Read unstructured data as tab delimited
birdsWCraw<- read_delim(file.path(data_path,
                                     "0002426-251025141854904",
                                     "occurrence.txt"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(birdsWCraw)
```

Create a cube from downloaded occurrence data

```{r}
# select columns required
birdsWC<- birdsWCraw %>% select (c('year', 'month', 'order', 'family', 'genus', 'speciesKey', 'species', 'decimalLatitude', 'decimalLongitude', 'coordinateUncertaintyInMeters'))
```

```{r}
# calculate the pentad based on co-ordinates and create a pentad column
# Note a function has also been written to do this, but is not implemented here

birdsWC<-birdsWC %>% separate(decimalLatitude, c("degreesLat", "otherLat"), "\\.", remove = FALSE)%>%
  mutate(otherLat = (as.numeric(paste0("0.", otherLat)))*60) %>%
  mutate(otherLat = sprintf('%02d', plyr::round_any(otherLat, 5, floor))) %>%
mutate(degreesLat = gsub("-","",degreesLat))  %>% 
  unite("pentadLat", degreesLat:otherLat, remove = TRUE, sep = "")
 
birdsWC<-birdsWC %>% separate(decimalLongitude, c("degreesLong", "otherLong"), "\\.", remove = FALSE)%>%
  mutate(otherLong = (as.numeric(paste0("0.", otherLong)))*60) %>%
  mutate(otherLong = sprintf('%02d', (plyr::round_any(otherLong, 5, floor)))) %>%
mutate(degreesLong = gsub("-","",degreesLong))  %>% 
  unite("pentadLong", degreesLong:otherLong, remove = TRUE, sep = "")  

birdsWC<-birdsWC %>% unite("pentad", c(pentadLat,pentadLong), sep = "_", remove = TRUE)
```

Prepare data for gcube

```{r}
# add time point for each observation based on year
birdsWC<- birdsWC %>% mutate (time_point = case_when(
  year == 2015  ~ 1,
  year == 2016  ~ 2,
  year == 2017  ~ 3,
  year == 2018  ~ 4,
  year == 2019  ~ 5,
  year == 2020  ~ 6,
  year == 2021  ~ 7,
  year == 2022  ~ 8,
  year == 2023  ~ 9,
  ))

# remove NA speciesKey, Assign NA coordinateUncertaintyInMeters to '8000m'
birdsWC <- birdsWC %>% 
  drop_na(speciesKey) %>% replace_na(list(coordinateUncertaintyInMeters = 8000))
```

```{r}
# create sf object
birdsWCsf <- st_as_sf(x = birdsWC,                         
               coords = c('decimalLongitude', 'decimalLatitude'), crs = st_crs(WCSFraw))
```

```{r}
# reproject to a flat co-ordinate reference system
birdsWCsfreproj <- st_transform(birdsWCsf, crs = "EPSG:32734") # EPSG:32734 is ideal for Western Cape
  
WCSFrawReproj<-st_transform(WCSFraw, crs = "EPSG:32734")
```

Create cube

```{r}
# Get species
taxa <- sort(unique(birdsWCsfreproj$species))

# Create empty list
occurrence_cube_list <- vector(mode = "list", length = length(taxa))

# Loop over species
for (i in seq_along(taxa)) {
  # Get species
  taxon <- taxa[i]
  
  # Filter data
  taxon_data <- birdsWCsfreproj %>%
    filter(taxon == species)
  
  # Perform grid designation
  taxon_cube <- grid_designation(
    observations = taxon_data,
    grid = WCSFrawReproj, seed = 123
  )
  
  # Add species column
  taxon_cube$species <- taxon
  
  # Add species cube to list
  occurrence_cube_list[[i]] <- taxon_cube
}

# Combine species cubes
occurrence_cube_full <- bind_rows(occurrence_cube_list)
```

structure cube in the same way as rgbif

```{r}
MissDeats<-birdsWCsfreproj %>%  st_drop_geometry() %>%
  select(order:species) %>%
  distinct()

birdcubeWCYearPentad <- occurrence_cube_full %>%
  st_drop_geometry() %>%
  filter(n != 0) %>% mutate (year = case_when(
  time_point == 1 ~ 2015,
  time_point == 2  ~ 2016,
  time_point == 3  ~ 2017,
  time_point == 4  ~ 2018,
  time_point == 5  ~ 2019,
  time_point == 6 ~ 2020,
  time_point == 7  ~ 2021,
  time_point == 8  ~ 2022,
  time_point == 9  ~ 2023,
  )) %>% select(n:pentad, species:year) %>% left_join(MissDeats)%>% rename(mincoordinateuncertaintyinmeters = min_coord_uncertainty)

fam<-birdcubeWCYearPentad %>% group_by(pentad, family) %>% summarise(familycount = sum(n))

ord<-birdcubeWCYearPentad %>% group_by(pentad, order) %>% summarise(ordercount = sum(n))

gen<-birdcubeWCYearPentad %>% group_by(pentad, genus) %>% summarise(genuscount = sum(n))

birdcubeWCYearPentad<-birdcubeWCYearPentad %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

# Subset datasets 

Select data falling into correct time period (2015-2023), and where full protocol was used for surveys (i.e., adhoc records in SABAP2 are removed). From cubes remove records with a minimum co-ordinate uncertainty of > 8 km for pentads (records with a minimum co-ordinate uncertainty of > 27 km were removed during the production of the qdgc cube)

## SABAP2 data for Western Cape

Select records from events where full sampling protocol followed (i.e., adhoc sampling removed)

Create a column called 'pentad'

Add a column with QDGC information

```{r}
# subset data to include only full protocol data
SABAP2WC<-SABAP2WCraw %>% filter(grepl("full", SABAP2WCraw$occurrenceID, fixed = TRUE))

# subset data to only include records from WC pentads (as per SABAP2 sampling framework)
WCpentads<-unique(WCSFraw$pentad) # pentads in WC
SABAP2WC <- SABAP2WC %>% filter(SABAP2WC$verbatimLocality %in% WCpentads)

# create new column called pentad
SABAP2WC <- SABAP2WC  %>%
  mutate(pentad = verbatimLocality)

# create new column called qdgccode
SABAP2WC <- SABAP2WC  %>%
  separate(locationRemarks, into = c('Long', 'Lat', 'Code'), sep = c(2,4), remove = FALSE) %>%
mutate(Long = paste0("S", Long))%>%
  mutate(Lat = paste0("E0", Lat))%>%
  unite(qdgccode, c(Lat,Long,Code), remove = TRUE, sep = "")

# remove duplicate cards for the same species & remove cards which are causing issues 

SABAP2WC<-SABAP2WC %>% distinct(species, fieldNotes, .keep_all = TRUE) %>% filter(fieldNotes != "3320_1900_012568_19000100") %>% filter(fieldNotes != "3325_1910_018033_20221029") %>% filter(fieldNotes != "3400_1935_018033_20230715")
```

## Sampling framework data for Western Cape

Select data from years between 2015 and 2023

Calculate number of full protocol sampling events

Add a column with QDGC information. Need to use a function 'get_qdgcCode()' to convert decimal degree co-ordinates to QDGC

```{r}
# Function to get quarter degree grid cell codes from decimal co-ordinates

get_qdgcCode <- function(lat, lon) {
  dirLon<-lon < 0 # true if longitude is negative
  dirLat<-lat < 0 # true if latitude is negative
  
  DegLonCod<-ifelse(dirLon == TRUE, "W", "E") # assign east/west
  DegLatCod<-ifelse(dirLat == TRUE, "S", "N") # assign north/south
  
  DegLon <- ifelse(dirLon == TRUE, -1*ceiling(lon), floor(lon)) # extract the integer from longitude (needs to be positive)
  DegLat <- ifelse(dirLat == TRUE, -1*ceiling(lat), floor(lat)) # extract the integer from latitude (needs to be positive)
  
  declat<-as.numeric(paste0("0.", unlist(stringr::str_split(lat, "\\."))[2])) # extract the fractional part of latitude
  declon<-as.numeric(paste0("0.", unlist(stringr::str_split(lon, "\\."))[2])) # extract the fractional part of longitude
  
  # Determine first code based on fractional portions
  
  DegCode<-ifelse(declat < 0.5 & declon < 0.5, "A", 
         ifelse(declat < 0.5 & declon > 0.5, "B",
         ifelse(declat > 0.5 & declon < 0.5, "C", "D")))
  
  # Determine second code based on fractional portions
  
  DegCode<-ifelse(declat < 0.5 & declon < 0.5, "A", 
                  ifelse(declat < 0.5 & declon > 0.5, "B",
                         ifelse(declat > 0.5 & declon < 0.5, "C", "D")))
 
  
  if(DegCode == "A"){
    QDegCode<-ifelse(declat < 0.25 & declon < 0.25, "A", 
           ifelse(declat < 0.25 & declon > 0.25, "B",
                  ifelse(declat > 0.25 & declon < 0.25, "C", "D")))
  }
  
 if(DegCode == "B"){
   QDegCode<-ifelse(declat < 0.25 & declon < 0.75, "A", 
           ifelse(declat < 0.25 & declon > 0.75, "B",
                  ifelse(declat > 0.25 & declon < 0.75, "C", "D")))
  }
  
  if(DegCode == "C"){
    QDegCode<-ifelse(declat < 0.75 & declon < 0.25, "A", 
           ifelse(declat < 0.75 & declon > 0.25, "B",
                  ifelse(declat > 0.75 & declon < 0.25, "C", "D")))
  }
  
  if(DegCode == "D"){
    QDegCode<-ifelse(declat < 0.75 & declon < 0.75, "A", 
           ifelse(declat < 0.75 & declon > 0.75, "B",
                  ifelse(declat > 0.75 & declon < 0.75, "C", "D")))
  }
  
  # Construct QDGC string
  
  paste0(DegLonCod, '0', DegLon, DegLatCod, DegLat, DegCode, QDegCode)
  
  }
```

```{r}
# subset data to include years between 2015 and 2023
WCSF<-WCSFraw %>% select(!(c('full proto':'2014','2024', '2025')))

# calculate number of full sampling protocols across years
WCSF<-WCSF %>%
  rowwise() %>%
  mutate(fullprotocol = sum(c_across('2015':'2023')))

# get co-ordinates of points in each pentad
WCSFcentroids <- st_centroid(WCSF)
WCSFcoords<-st_coordinates(WCSFcentroids)

# use get_qdgcCode function to get qdgc codes from co-ordinates
WCSF$qdgccode<-apply(WCSFcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

## Bird occurrence cube for Western Cape at QDGC

The occurrence cube includes data for grid cells falling outside of the Western Cape. Therefore WC cells are selected

```{r}
# subset cube to only include QDGC from Western Cape

WCQDGC<-unique(WCSF$qdgccode) # QDGC in Western Cape

birdcubeWCYearQDGC <- birdcubeWCYearQDGC %>% filter(birdcubeWCYearQDGC$qdgccode %in% WCQDGC)
```

## Bird occurrence cube for Western Cape at Pentad scale

Exclude data that have mincoordinateuncertaintyinmeters > 8 km

```{r}
# Subset data to only include records with min co-ordinate uncertainty of <= 8 km
birdcubeWCYearPentad <- birdcubeWCYearPentad %>% filter(mincoordinateuncertaintyinmeters <=8000)
```

# Create SABAP2 cubes with sample data

## SABAP2 QDGC cube

```{r}
# filter out na species, classify commonness, Group by species, year and qdgccode
SABAP2WCQDGCYear <-SABAP2WC %>% filter(!is.na(species)) %>%
  group_by(species) %>%
  mutate(n_obs = n()) %>%
  ungroup() %>%
  mutate(category = cut(n_obs,
                        breaks = c(0, 10, 100, 1000, 10000, +Inf),
                        labels = c("Very rare", "Rare", "Common",
                                   "Very common", "Extremely common"),
                        right = FALSE)) %>%
  group_by(species, family, order, genus, year , speciesKey, qdgccode, category) %>%
  summarise(n = n())

# counts for genera, family, order
fam<-SABAP2WCQDGCYear %>% group_by(qdgccode, family) %>% summarise(familycount = sum(n))

ord<-SABAP2WCQDGCYear %>% group_by(qdgccode, order) %>% summarise(ordercount = sum(n))

gen<-SABAP2WCQDGCYear %>% group_by(qdgccode, genus) %>% summarise(genuscount = sum(n))

SABAP2WCQDGCYear<-SABAP2WCQDGCYear %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

```{r}
# Sampling data: drop geometry and get number of samples per QDGC
QDGCSamp<-WCSF %>% st_drop_geometry() %>% 
group_by(qdgccode) %>%
            summarise_at(vars('2015':'2023', 'fullprotocol'), sum)

# make a long-form
QDGCSampLong <-  QDGCSamp %>%  pivot_longer(cols = "2015":"2023", names_to = "year", values_to = "totalYear", names_transform = list(year = as.integer))

# join datasets
SABAP2WCQDGCYearSamp<-SABAP2WCQDGCYear %>% left_join(QDGCSampLong, by = join_by(qdgccode, year)) %>% ungroup()

# check that samples and no records make sense
test<-SABAP2WCQDGCYearSamp$n<=SABAP2WCQDGCYearSamp$totalYear
tmp<-which(test == FALSE)
issues<-SABAP2WCQDGCYearSamp[tmp,]
```

## SABAP2 QDGC for iNEXT

```{r}
# Group by species, and QDGC, and reformat for iNEXT
SABAP2WCQDGCWide <-SABAP2WC %>% 
  group_by(species, speciesKey, qdgccode) %>%
  summarise(n = n()) %>% 
  ungroup() %>%
  pivot_wider(names_from = qdgccode, values_from = n, values_fill = 0) %>%
  select(!(species:speciesKey))

# make a similar wide dataset with full protocol counts
WCQDGCSamp<-QDGCSamp %>% select(fullprotocol, qdgccode) %>% unique() %>%  
  pivot_wider(names_from = qdgccode, values_from = fullprotocol)

# remove cells not in surveys
WCQDGCSamp<- WCQDGCSamp %>%  select(matches(names(SABAP2WCQDGCWide)))

# bind datasets together and make into list
WCQDGCincid<-rbind(WCQDGCSamp, SABAP2WCQDGCWide) %>% as.list()
```

### Calculate sample coverage for each cell.

```{r}
# Remove grids where there has been only one survey, as causes an error in iNEXT
WCQDGCincidSub<-WCQDGCincid[sapply(WCQDGCincid, function(x) x[1] > 2)] # there are nine of these grid cells

# run iNEXT (note it does take some time)
WCQDGCSC <- iNEXT(WCQDGCincidSub, q=0, datatype="incidence_freq")

# Visualise and get values for range of number of surveys
hist(WCQDGCSC$DataInfo$T) # histogram of number of surveys
range(WCQDGCSC$DataInfo$T) # range of values

# Visualise and get values sample coverage
hist(WCQDGCSC$DataInfo$SC)# histogram of sample coverage for the grid cells
range(WCQDGCSC$DataInfo$SC) # range of values
summary(WCQDGCSC$DataInfo$SC) # summary of sample coverage


# There are relatively few grid cells for which coverage is low. This has implications for later analyses, so these will be removed
```

### Remove cells with < 0.9 sample coverage

```{r}
highSamp<- WCQDGCSC$DataInfo %>% filter(SC >= 0.90)

# Remove grid cells from structured data cube
SABAP2WCQDGCYearSamp<-SABAP2WCQDGCYearSamp %>% filter (qdgccode %in% highSamp$Assemblage)

# Remove grid cells from incidence data for iNEXT
WCQDGCincid <- WCQDGCincidSub[names(WCQDGCincidSub) %in% highSamp$Assemblage]
```

```{r}
# Remove cells from unstructured data cube that have been removed from SABAP2 due to lower sample coverage
birdcubeWCYearQDGC<-birdcubeWCYearQDGC %>% filter (qdgccode %in% highSamp$Assemblage)
```


## SABAP2 pentad cube

```{r}
# filter out na species, classify commonness, Group by species, year and qdgccode
SABAP2WCPenYear <-SABAP2WC %>% filter(!is.na(species)) %>%
  group_by(species) %>%
  mutate(n_obs = n()) %>%
  ungroup() %>%
  mutate(category = cut(n_obs,
                        breaks = c(0, 10, 100, 1000, 10000, +Inf),
                        labels = c("Very rare", "Rare", "Common",
                                   "Very common", "Extremely common"),
                        right = FALSE)) %>%
  group_by(species, family, order, genus, year, speciesKey, pentad, category) %>%
  summarise(n = n())

# counts for genera, family, order
fam<-SABAP2WCPenYear %>% group_by(pentad, family) %>% summarise(familycount = sum(n))

ord<-SABAP2WCPenYear %>% group_by(pentad, order) %>% summarise(ordercount = sum(n))

gen<-SABAP2WCPenYear %>% group_by(pentad, genus) %>% summarise(genuscount = sum(n))

SABAP2WCPenYear<-SABAP2WCPenYear %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

```{r}
# Sampling data: drop geometry and get number of samples per pentad
PenSamp<-WCSF %>% st_drop_geometry() %>% 
group_by(pentad) %>%
            summarise_at(vars('2015':'2023', 'fullprotocol'), sum)

# make a long-form
PenSampLong <-  PenSamp %>%  pivot_longer(cols = "2015":"2023", names_to = "year", values_to = "totalYear", names_transform = list(year = as.integer))

# join datasets
SABAP2WCPenYearSamp<-SABAP2WCPenYear %>% left_join(PenSampLong, by = join_by(pentad, year))  %>% ungroup()

# check that samples and no records make sense
test<-SABAP2WCPenYearSamp$n<=SABAP2WCPenYearSamp$totalYear
tmp<-which(test == FALSE)
issues<-SABAP2WCPenYearSamp[tmp,]
```

## SABAP2 pentads for iNEXT

```{r}
# Group by species, and pentad, and reformat for iNEXT
SABAP2WCPenWide <-SABAP2WC %>% 
  group_by(species, speciesKey, pentad) %>%
  summarise(n = n()) %>% 
  ungroup() %>%
  pivot_wider(names_from = pentad, values_from = n, values_fill = 0) %>%
  select(!(species:speciesKey))

# make a similar wide dataset with full protocol counts
WCPenSamp<-PenSamp %>% select(fullprotocol, pentad) %>% unique() %>%  
  pivot_wider(names_from = pentad, values_from = fullprotocol)

# remove cells not in surveys
WCPenSamp<- WCPenSamp %>%  select(matches(names(SABAP2WCPenWide)))

# bind datasets together and make into list
WCPenincid<-rbind(WCPenSamp, SABAP2WCPenWide) %>% as.list()
```

### Calculate sample coverage for each cell

```{r}
# Remove grid cells where there has been only two surveys, as causes an error in iNEXT
WCPenincidSub<-WCPenincid[sapply(WCPenincid, function(x) x[1] > 2)] # there are 416 of these grid cells (out of 1518)

WCPenSC <- iNEXT(WCPenincidSub, q=0, datatype="incidence_freq")

# Visualise and get values for range of number of surveys
hist(WCPenSC$DataInfo$T) # histogram of number of surveys
range(WCPenSC$DataInfo$T) # range of values

# Visualise and get values sample coverage
hist(WCPenSC$DataInfo$SC)# histogram of sample coverage for the grid cells
range(WCPenSC$DataInfo$SC) # range of values
summary(WCPenSC$DataInfo$SC) # summary of sample coverage

# There are relatively few grid cells for which coverage is low. This has implications for later analyses, so these will be removed
```

### Remove cells with < 0.9 sample coverage

```{r}
highSampPen<- WCPenSC$DataInfo %>% filter(SC >= 0.90)

# Remove grid cells from structured data cube
SABAP2WCPenYearSamp<-SABAP2WCPenYearSamp %>% filter (pentad %in% highSampPen$Assemblage)

# Remove grid cells from incidence data for iNEXT
WCPenincid <- WCPenincidSub[names(WCPenincidSub) %in% highSampPen$Assemblage]
```

```{r}
# Remove cells from unstructured data cube that have been removed from SABAP2 due to lower sample coverage
birdcubeWCYearPentad<-birdcubeWCYearPentad %>% filter (pentad %in% highSampPen$Assemblage)
```

# Write data to file

```{r}
out_path <- here::here("data", "interim")
dir.create(out_path, showWarnings = FALSE, recursive = TRUE)

# Structured data at QDGC scale
write.csv(SABAP2WCQDGCYearSamp, file.path(out_path, "SABAP2_QDGC_WC_data.csv"), row.names = F)

# Structured data at QDGC scale for iNEXT
saveRDS(WCQDGCincid, file.path(out_path, "SABAP2_QDGC_WC_iNEXT.rds"))

# Unstructured data at QDGC scale
write.csv(birdcubeWCYearQDGC, file.path(out_path, "Unstruc_QDGC_WC_data.csv"), row.names = F)

# Structured data at pentad scale
write.csv(SABAP2WCPenYearSamp, file.path(out_path, "SABAP2_Pentad_WC_data.csv"), row.names = F)

# Structured data at pentad scale for iNEXT
saveRDS(WCPenincid, file.path(out_path, "SABAP2_Pentad_WC_iNEXT.rds"))

# Unstructured data at pentad scale
write.csv(birdcubeWCYearPentad, file.path(out_path, "Unstruc_Pentad_WC_data.csv"), row.names = F)
```

# Basic data exploration

## Structured data

### Number of surveys per year

Quarter degree grid cells

```{r}
SABAP2WCQDGCYearSamp %>% select(year, qdgccode, totalYear) %>% unique() %>%  group_by(year) %>% summarise(n = sum(totalYear)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of surveys")
```

Pentads

```{r}
SABAP2WCPenYearSamp %>% select(year, pentad, totalYear) %>% unique() %>%  group_by(year) %>% summarise(n = sum(totalYear)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of surveys")
```

### Number of observations per year

Quarter degree grid cells

```{r}
SABAP2WCQDGCYearSamp %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

Pentads

```{r}
SABAP2WCPenYearSamp %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

### Number of surveys per grid cell

Quarter degree grid cells

```{r}
SABAP2WCQDGCYearSamp %>% select(qdgccode, fullprotocol) %>% unique() %>%
  group_by(qdgccode) %>%
    summarise(n = sum(fullprotocol)) %>%
  ggplot(aes(x = n)) +
  geom_histogram(fill = "#D95F02", color = "black") +
  labs(x = "Number of surveys",
       y = "Number of quarter-degree grid cells")
```

Pentads

```{r}
SABAP2WCPenYearSamp %>% select(pentad, fullprotocol) %>%unique() %>%
  group_by(pentad) %>%
    summarise(n = sum(fullprotocol)) %>%
  ggplot(aes(x = n)) +
  geom_histogram(fill = "#D95F02", color = "black") +
  labs(x = "Number of surveys",
       y = "Number of pentad grid cells")
```

## Unstructured data

### Number of observations per year

Quarter degree grid cells

```{r}
birdcubeWCYearQDGC %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

Pentads

```{r}
birdcubeWCYearPentad %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```


# Calculation of metrics and comparison

```{r}
# Create a custom color scale
library(RColorBrewer)
myColors <- brewer.pal(5, "Dark2")
names(myColors) <- c("Very rare", "Rare", "Common",
                     "Very common", "Extremely common")
colScale <- scale_color_manual(name = "Category",
                                values = myColors)
fillScale <- scale_fill_manual(name = "Category",
                                values = myColors)
```

## Range

### QDGC

```{r}
# species recorded in sabap2
studied_spec <- unique(SABAP2WCQDGCYearSamp$species) %>%
  na.omit()
```

```{r}
# function to compare ranges
range_comp <- function(sel_species, period = 2015:2023,
                       dataset1 = SABAP2WCQDGCYearSamp,
                       dataset2 = birdcubeWCYearQDGC) {

  # We filter both datasets for the species and period of interest
  # and group them by QDGC
  set_sabap2 <- dataset1 %>%
      filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$qdgccode) %>%
    summarise(n = n()) # no observations rather than no individuals

  set_cube <- dataset2 %>%
    filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$qdgccode) %>%
    summarise(n = sum(.data$n))

  total_sabap2 <- length(set_sabap2$qdgccode)
  perc_sabap2 <- (total_sabap2 / 247) * 100 # have taken the value to be total number of grid cells in area of interest
  
  total_cube <- length(set_cube$qdgccode)
  perc_cube <- (total_cube / 247) * 100 # have taken the value to be total number of grid cells in area of interest

  overlap_all_sabap2_cube <- length(
    which(set_cube$qdgccode %in% unique(dataset1$qdgccode))
    )
  perc_overlap_all <- (overlap_all_sabap2_cube / 247) * 100 # have taken the value to be total number of grid cells in the sabap2 data

  total_overlap <- length(which(set_cube$qdgccode %in% set_sabap2$qdgccode))
  perc <- (total_overlap / total_sabap2) * 100 

  list(total_sabap2, perc_sabap2,
       total_cube, perc_cube,
       overlap_all_sabap2_cube, perc_overlap_all,
       total_overlap, perc)
}
```

```{r}
# run function
comp_range_data <- as.data.frame(studied_spec)
comp_range_data$sabap2_squares <- NA
comp_range_data$perc_sabap2_total_sabap2 <- NA
comp_range_data$cube_squares <- NA
comp_range_data$perc_cube_total_cube <- NA
comp_range_data$overlap_birdcube_total_sabap2 <- NA
comp_range_data$perc_birdcube_total_sabap2 <- NA
comp_range_data$overlap_birdcube_spec_sabap2 <- NA
comp_range_data$percentage_birdcube_spec_sabap2 <- NA

for (i in studied_spec){
  test <- range_comp(i, period = 2015:2023)
  
  comp_range_data[comp_range_data$studied_spec == i, 2] <- test[1]
  comp_range_data[comp_range_data$studied_spec == i, 3] <- test[2]
  comp_range_data[comp_range_data$studied_spec == i, 4] <- test[3]
  comp_range_data[comp_range_data$studied_spec == i, 5] <- test[4]
  comp_range_data[comp_range_data$studied_spec == i, 6] <- test[5]
  comp_range_data[comp_range_data$studied_spec == i, 7] <- test[6]
  comp_range_data[comp_range_data$studied_spec == i, 8] <- test[7]
  comp_range_data[comp_range_data$studied_spec == i, 9] <- test[8]
}
```

```{r}
# summary of output
summary(comp_range_data)
```

Overall we see a range overlap of 69%

Range overlap

```{r}
# plot percentage range overlap
comp_range_data %>%
  inner_join(SABAP2WCQDGCYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = percentage_birdcube_spec_sabap2,fill = category)) +
  geom_histogram() +
  fillScale +
  labs(x = "Percentage range overlap",
       y = "Number of species")
```

Range size

```{r}
# Plot number of grid cells in which species recorded in SABAP2 vs number of cells in which recorded in unstructured data
comp_range_data %>%
  inner_join(SABAP2WCQDGCYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = sabap2_squares, y = cube_squares, color = category)) +
  geom_point() +
  colScale +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson")+
  labs(x = "Number of squares occupied\nby species in SABAP2 dataset",
       y = "Number of squares occupied\nby species in cube dataset")
```

## Pentad

```{r}
# species recorded in sabap2
studied_spec <- unique(SABAP2WCPenYearSamp$species) %>%
  na.omit()
```

```{r}
# function to compare ranges
range_comp <- function(sel_species, period = 2015:2023,
                       dataset1 = SABAP2WCPenYearSamp,
                       dataset2 = birdcubeWCYearPentad) {

  # We filter both datasets for the species and period of interest
  # and group them by pentad
  set_sabap2 <- dataset1 %>%
      filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$pentad) %>%
    summarise(n = n()) # no observations rather than no individuals

  set_cube <- dataset2 %>%
    filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$pentad) %>%
    summarise(n = sum(.data$n))

  total_sabap2 <- length(set_sabap2$pentad)
  perc_sabap2 <- (total_sabap2 / 1842) * 100 # have taken the value to be total number of grid cells in area of interest
  
  total_cube <- length(set_cube$pentad)
  perc_cube <- (total_cube / 1842) * 100 # have taken the value to be total number of grid cells in area of interest

  overlap_all_sabap2_cube <- length(
    which(set_cube$pentad %in% unique(dataset1$pentad))
    )
  perc_overlap_all <- (overlap_all_sabap2_cube / 1842) * 100 # have taken the value to be total number of grid cells in the sabap2 data

  total_overlap <- length(which(set_cube$pentad %in% set_sabap2$pentad))
  perc <- (total_overlap / total_sabap2) * 100 

  list(total_sabap2, perc_sabap2,
       total_cube, perc_cube,
       overlap_all_sabap2_cube, perc_overlap_all,
       total_overlap, perc)
}
```

```{r}
# run function
comp_range_data <- as.data.frame(studied_spec)
comp_range_data$sabap2_squares <- NA
comp_range_data$perc_sabap2_total_sabap2 <- NA
comp_range_data$cube_squares <- NA
comp_range_data$perc_cube_total_cube <- NA
comp_range_data$overlap_birdcube_total_sabap2 <- NA
comp_range_data$perc_birdcube_total_sabap2 <- NA
comp_range_data$overlap_birdcube_spec_sabap2 <- NA
comp_range_data$percentage_birdcube_spec_sabap2 <- NA

for (i in studied_spec){
  test <- range_comp(i, period = 2015:2023)
  
  comp_range_data[comp_range_data$studied_spec == i, 2] <- test[1]
  comp_range_data[comp_range_data$studied_spec == i, 3] <- test[2]
  comp_range_data[comp_range_data$studied_spec == i, 4] <- test[3]
  comp_range_data[comp_range_data$studied_spec == i, 5] <- test[4]
  comp_range_data[comp_range_data$studied_spec == i, 6] <- test[5]
  comp_range_data[comp_range_data$studied_spec == i, 7] <- test[6]
  comp_range_data[comp_range_data$studied_spec == i, 8] <- test[7]
  comp_range_data[comp_range_data$studied_spec == i, 9] <- test[8]
}
```

```{r}
# summary of output
summary(comp_range_data)
```

Overall we see a range overlap of 52%

Range overlap

```{r}
# plot percentage range overlap
comp_range_data %>%
  inner_join(SABAP2WCPenYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = percentage_birdcube_spec_sabap2,fill = category)) +
  geom_histogram() +
  fillScale +
  labs(x = "Percentage range overlap",
       y = "Number of species")
```

Range size

```{r}
# Plot number of grid cells in which species recorded in SABAP2 vs number of cells in which recorded in unstructured data
comp_range_data %>%
  inner_join(SABAP2WCPenYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = sabap2_squares, y = cube_squares, color = category)) +
  geom_point() +
  colScale +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson")+
  labs(x = "Number of squares occupied\nby species in SABAP2 dataset",
       y = "Number of squares occupied\nby species in cube dataset")
```

## b3gbi indicators

### Process cubes

Unstructured data at QDGC

```{r}
WCunstrucQDGCproc <- process_cube(birdcubeWCYearQDGC, grid_type = 'eqdgc', first_year = 2015, cols_year =  'year', cols_cellCode = 'qdgccode', cols_occurrences = 'n',  cols_minCoordinateUncertaintyInMeters	
= 'mincoordinateuncertaintyinmeters', cols_familyCount = 'familycount', cols_speciesKey = 'specieskey')
```

Structured data at QDGC

```{r}
WCStrucQDGCproc <- process_cube(SABAP2WCQDGCYearSamp, grid_type = 'eqdgc', first_year = 2015, cols_year =  'year', cols_cellCode = 'qdgccode', cols_occurrences = 'n', cols_speciesKey = 'speciesKey', cols_familyCount = 'familycount')
```

Unstructured data for pentads

```{r}
WCunstrucPenproc <- process_cube(birdcubeWCYearPentad, grid_type = 'custom', first_year = 2015, cols_year =  'year', cols_cellCode = 'pentad', cols_occurrences = 'n',  cols_minCoordinateUncertaintyInMeters 
= 'mincoordinateuncertaintyinmeters', cols_familyCount = 'familycount', cols_speciesKey = 'speciesKey')
```

Structured data for pentads

```{r}
WCstrucPenproc <- process_cube(SABAP2WCPenYearSamp, grid_type = 'custom', first_year = 2015, cols_year =  'year', cols_cellCode = 'pentad', cols_occurrences = 'n',  cols_familyCount = 'familycount', cols_speciesKey = 'speciesKey')
```

### Total occurrences

Unstructured data QDGC

```{r}
map_obs_WC_QDGCU <- total_occ_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_WC_QDGCU, title = "Number of records - unstructured data")
```

Structured data QDGC

```{r}
map_obs_WC_QDGCS <- total_occ_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_WC_QDGCS, title = "Number of records - structured data")
```

Compare

```{r}
# Plot number of records structured vs unstructured data
map_obs_WC_QDGCS$data %>% st_drop_geometry() %>% 
   inner_join(map_obs_WC_QDGCU$data,
            by = join_by(cellid)) %>%
  ggplot(aes(x = diversity_val.x, y = diversity_val.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records - structured data",
       y = "Number of records - unstructured data")
```

Unstructured data pentads - note not possible through b3gbi

```{r}
obs_WC_PenU<-birdcubeWCYearPentad %>% group_by(pentad) %>% summarise(Obs = sum(n))
```

Structured data pentads - not not possible through b3gbi

```{r}
obs_WC_PenS<-SABAP2WCPenYearSamp %>% group_by(pentad, fullprotocol) %>% summarise(Obs = sum(n)) %>% mutate(Obseff = Obs/fullprotocol)
```

Compare

```{r}
# Plot number of records structured vs unstructured data
obs_WC_PenS %>% 
   inner_join(obs_WC_PenU,
            by = join_by(pentad)) %>%
  ggplot(aes(x = Obs.x, y = Obs.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records - structured data",
       y = "Number of records - unstructured data")
```


### Total occurrences (structured data corrected for sample effort)

QDGC

```{r}
obs_WC_QDGCSeff<-SABAP2WCQDGCYearSamp %>% group_by(qdgccode, fullprotocol) %>% summarise(Obs = sum(n)) %>% mutate(Obseff = Obs/fullprotocol)
```

Compare - QDGC

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

map_obs_WC_QDGCU$data$qdgccode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot number of records for structured data corrected for survey effort vs unstructured data
obs_WC_QDGCSeff %>% 
   inner_join(map_obs_WC_QDGCU$data,
            by = join_by(qdgccode)) %>%
  ggplot(aes(x = Obseff, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records/number of surveys - structured data",
       y = "Number of records - unstructured data")
```

Pentad

```{r}
# Plot number of records structured corrected for survey effort vs unstructured data
obs_WC_PenS %>% 
   inner_join(obs_WC_PenU,
            by = join_by(pentad)) %>%
  ggplot(aes(x = Obseff, y = Obs.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records/number of surveys - structured data",
       y = "Number of records - unstructured data")
```

### Observed richness

Unstructured data QDGC

```{r}
map_obs_rich_WC_QDGCU <- obs_richness_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_rich_WC_QDGCU, title = "Observed Bird Species Richness - unstructured data")
```

Structured data QDGC

```{r}
map_obs_rich_WC_QDGCS <- obs_richness_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_rich_WC_QDGCS, title = "Observed Bird Species Richness - structured data")
```

Compare

```{r}
# Plot observed richness structured vs unstructured data
map_obs_rich_WC_QDGCS$data %>% st_drop_geometry() %>% 
   inner_join(map_obs_rich_WC_QDGCU$data,
            by = join_by(cellid)) %>%
  ggplot(aes(x = diversity_val.x, y = diversity_val.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Observed richness - structured data",
       y = "Observed richness - unstructured data")
```

Unstructured data pentads (note not possible through b3gbi as a bespoke grid)

```{r}
obs_rich_WC_PenU <- WCunstrucPenproc$data %>% group_by(cellCode) %>%
              summarise(n_species = n_distinct(scientificName), .groups = "drop")
```

Structured data pentads (note not possible through b3gbi as a bespoke grid)

```{r}
obs_rich_WC_PenS <- WCstrucPenproc$data %>% group_by(cellCode) %>%
              summarise(n_species = n_distinct(scientificName), .groups = "drop")
```

Compare

```{r}
# Plot observed richness structured vs unstructured data
obs_rich_WC_PenS %>%  
   inner_join(obs_rich_WC_PenU,
            by = join_by(cellCode)) %>%
  ggplot(aes(x = n_species.x, y = n_species.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Observed richness - structured data",
       y = "Observed richness - unstructured data")
```

### Estimated richness - based on incidence data (structured and unstructured)

Unstructured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_WC_QDGCU <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence")) 
plot(hill0_map_WC_QDGCU, title = "Estimated Bird Species Richness - unstructured data (0.95 coverage - incidence)")
```

Structured QDGC - b3gbi with default settings and assume_freq = F

```{r}
# with default settings (coverage 0.95)
hill0_map_WC_QDGCS <- hill0_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence"))

plot(hill0_map_WC_QDGCS, title = "Estimated Bird Species Richness - structured data (0.95 coverage - incidence)")
```

Structured QDGC - b3gbi with default settings and assume_freq = F

```{r}
# with default settings (coverage 0.95)
hill0_map_WC_QDGCSas <- hill0_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence"), assume_freq = T)

plot(hill0_map_WC_QDGCSas, title = "Estimated Bird Species Richness - structured data (0.95 coverage - incidence)")
```

Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
inEXTestsWCQDGCS<-estimateD(WCQDGCincid, datatype="incidence_freq",
          base="coverage", level=NULL, conf=0.95) # If base="coverage" and level=NULL, then this function computes the diversity estimates for the minimum among the coverage values for samples extrapolated to double the size of the reference sample.

# note the level implemented is 0.945527

richEstsWCQDGCS<-inEXTestsWCQDGCS %>% filter(Order.q == 0)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_rich_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

map_obs_rich_WC_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_WC_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_WC_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_WC_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot observed richness from unstructured data and estimated richness from iNEXT from structured data
richEstsWCQDGCS %>% 
   inner_join(map_obs_rich_WC_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945)",
       y = "Observed richness - unstructured data (b3gbi)")
```

```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95) and estimated richness from iNEXT for structured data (0.94) (assume_freq = F for b3gbi)
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945)",
       y = "Estimated richness - structured data (b3gbi - 0.95)")
```

```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95) and estimated richness from iNEXT for structured data (0.94) (assume_freq = T for b3gbi)
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945)",
       y = "Estimated richness - structured data (b3gbi - 0.95)")
```

```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.95) and estimated richness from iNEXT for structured data (coverage 0.94)
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945)",
       y = "Estimated richness - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- map_obs_rich_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate richness for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill0 <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium",  coverage = i, data_type = "incidence") 
  hill0 <- hill0$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill0[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate richness for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-richEstsWCQDGCS %>% filter(Order.q == 0) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

EstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")
 
# plot correlation
corrplot(EstCor, method="circle")

# largest correlation
ind<-which(EstCor==max(EstCor),arr.ind = TRUE)
rownames(EstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.05) for unstructured data
hill0_map_WC_QDGCU05 <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.05, data_type = "incidence") 
plot(hill0_map_WC_QDGCU05, title = "Estimated Bird Species Richness - unstructured data (0.05 coverage)")
```

Compare estimates

```{r}
hill0_map_WC_QDGCU05$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.05) and estimated richness from iNEXT (0.94) from structured data
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCU05$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945)",
       y = "Estimated richness - unstructured data (b3gbi - 0.05)")
```

Structured data for pentads - calculated with iNEXT (i.e., actual survey effort used)

```{r}
inEXTestsWCPenS<-estimateD(WCPenincid, datatype="incidence_freq",
          base="coverage", level=NULL, conf=0.95) # If base="coverage" and level=NULL, then this function computes the diversity estimates for the minimum among the coverage values for samples extrapolated to double the size of the reference sample.

# note the level implemented is 0.934881

inEXTestsWCPenS<-inEXTestsWCPenS %>% filter(Order.q == 0)
```

Compare estimates

```{r}
# Plot observed richness from unstructured data and estimated richness from iNEXT from structured data
inEXTestsWCPenS %>% 
   inner_join(obs_rich_WC_PenU,
            by = join_by(Assemblage == cellCode)) %>%
  ggplot(aes(x = qD, y = n_species)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.93)",
       y = "Observed richness - unstructured data")
```

# Hill-Shannon Diversity (only possible for QDGC) - based on incidence data (structured and unstructured)

Unstructured data for QDGC - with default settings using b3gbi. 

```{r}
# with default settings (coverage 0.95)
hill1_map_WC_QDGCU <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill1_map_WC_QDGCU, title = "Shannon Diversity - unstructured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi. Assume_freq = T

```{r}
# with default settings (coverage 0.95)
hill1_map_WC_QDGCS <- hill1_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence", assume_freq = F)
plot(hill1_map_WC_QDGCS, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi. Assume_freq = T

```{r}
# with default settings (coverage 0.95)
hill1_map_WC_QDGCSas <- hill1_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence", assume_freq = T)
plot(hill1_map_WC_QDGCSas, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
hill1EstsWCQDGCS<-inEXTestsWCQDGCS %>% filter(Order.q == 1)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill1_map_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill1_map_WC_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_WC_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_WC_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data (assume_freq = F)
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.945)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95 (incidence))")
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data (assume_freq = F)
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.945)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95 (incidence))")
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data (assume_freq = T)
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.94)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95 (incidence))")
```


```{r}
# Plot Shannon Diversity for unstructured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.945)",
       y = "Shannon Diversity - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill1_map_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate shannon diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill1 <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence",  coverage = i, cutoff_length = 10)
  hill1 <- hill1$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill1[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate shannon diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsWCQDGCS %>% filter(Order.q == 1) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

ShanEstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")

# plot correlation
corrplot(ShanEstCor, method="circle")

# largest correlation
ind<-which(ShanEstCor==max(ShanEstCor),arr.ind = TRUE)
rownames(ShanEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.05) for unstructured data
hill1_map_WC_QDGCU05 <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.05, data_type = "incidence") 
plot(hill1_map_WC_QDGCU05, title = "Shannon diversity - unstructured data (0.05 coverage)")
```

Compare estimates

```{r}
hill1_map_WC_QDGCU05$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot shannon diversity from unstructured data (b3gbi - coverage 0.05) and shannon diversity from iNEXT (0.94) from structured data
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCU05$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon diversity - structured data (iNEXT - 0.945)",
       y = "Shannon diversity - unstructured (b3gbi - 0.05)")
```

# Hill-Simpson Diversity (only possible for QDGC) - based on incidence data (structured and unstructured)

Unstructured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_WC_QDGCU <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill2_map_WC_QDGCU, title = "Simpson Diversity - unstructured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi (assume_freq = F)

```{r}
# with default settings (coverage 0.95)
hill2_map_WC_QDGCS <- hill2_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill2_map_WC_QDGCS, title = "Simpson Diversity - structured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi (assume_freq = T)

```{r}
# with default settings (coverage 0.95)
hill2_map_WC_QDGCSas <- hill2_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence", assume_freq = T) 
plot(hill2_map_WC_QDGCSas, title = "Simpson Diversity - structured data (0.95 coverage)")
```

Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
hill2EstsWCQDGCS<-inEXTestsWCQDGCS %>% filter(Order.q == 2)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill2_map_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill2_map_WC_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_WC_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_WC_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Simpson Diversity for structured data estimated using b3gbi and Simpson Diversity from iNEXT for structured data (assume_freq = F for b3gbi)
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.945)",
       y = "Simpson Diversity - structured data (b3gbi -0.95)")
```

```{r}
# Plot Simpson Diversity for structured data estimated using b3gbi and Simpson Diversity from iNEXT for structured data (assume_freq = T for b3gbi)
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.945)",
       y = "Simpson Diversity - structured data (b3gbi -0.95)")
```

```{r}
# Plot Simpson Diversity for unstructured data estimated using b3gbi and Simpson Diversity from iNEXT from structured data
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.945)",
       y = "Simpson Diversity - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill2_map_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate simpson diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill2 <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence",  coverage = i)
  hill2 <- hill2$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill2[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate simpson diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsWCQDGCS %>% filter(Order.q == 2) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

SimpEstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")

# plot correlation
corrplot(SimpEstCor, method="circle")

# largest correlation
ind<-which(SimpEstCor==max(SimpEstCor),arr.ind = TRUE)
rownames(SimpEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.05) for unstructured data
hill2_map_WC_QDGCU05 <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.05, data_type = "incidence") 
plot(hill2_map_WC_QDGCU05, title = "Simpson diversity - unstructured data (0.05 coverage)")
```

Compare estimates

```{r}
hill2_map_WC_QDGCU05$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot simpson diversity from unstructured data (b3gbi - coverage 0.05) and simpson diversity from iNEXT (0.94) from structured data
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCU05$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson diversity - structured data (iNEXT - 0.945)",
       y = "Simpson diversity - unstructured data (b3gbi - 0.05)")
```

### Estimated richness - based on incidence data (structured) abundance data (unstructured)

Unstructured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_WC_QDGCUAb <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("abundance")) 
plot(hill0_map_WC_QDGCUAb, title = "Estimated Bird Species Richness - unstructured data (0.95 coverage)")
```

Structured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_WC_QDGCSAb <- hill0_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("abundance")) 
plot(hill0_map_WC_QDGCSAb, title = "Estimated Bird Species Richness - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_rich_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill0_map_WC_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_WC_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```


```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95 using abundance) and estimated richness from iNEXT for structured data using incidence
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.945 - incidence)",
       y = "Estimated richness - structured data (b3gbi - 0.95 - abundance)")
```

```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.95, abundance) and estimated richness from iNEXT for structured data (incidence)
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT (incidence) - 0.945)",
       y = "Estimated richness - unstructured data (b3gbi(abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- map_obs_rich_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate richness for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill0 <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium",  coverage = i, data_type = "abundance") 
  hill0 <- hill0$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill0[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate richness for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-richEstsWCQDGCS %>% filter(Order.q == 0) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

EstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")

# plot correlation
corrplot(EstCor, method="circle")

# largest correlation
ind<-which(EstCor==max(EstCor),arr.ind = TRUE)
rownames(EstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.95) for unstructured data
hill0_map_WC_QDGCU95Ab <- hill0_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.95, data_type = "abundance") 
plot(hill0_map_WC_QDGCU95Ab, title = "Estimated Bird Species Richness - unstructured data (0.95 coverage)")
```

Compare estimates

```{r}
hill0_map_WC_QDGCU95Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot estimated richness for unstructured data (b3gbi (abundance) - coverage 0.95) and estimated richness from iNEXT (incidence - 0.995 ) from structured data
richEstsWCQDGCS %>% 
   inner_join(hill0_map_WC_QDGCU95Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT (incidence) - 0.945)",
       y = "Estimated richness - unstructured data (b3gbi (abundance) - 0.95)")
```

# Hill-Shannon Diversity (only possible for QDGC) - based on incidence (structured) and abundance (unstructured)

Unstructured data for QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill1_map_WC_QDGCUAb <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill1_map_WC_QDGCUAb, title = "Shannon Diversity - unstructured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill1_map_WC_QDGCSAb <- hill1_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill1_map_WC_QDGCSAb, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill1_map_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill1_map_WC_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_WC_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.945)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95)")
```


```{r}
# Plot Shannon Diversity for unstructured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT (incidence) - 0.945)",
       y = "Shannon Diversity - unstructured data (b3gbi (abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill1_map_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate shannon diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill1 <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance",  coverage = i)
  hill1 <- hill1$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill1[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate shannon diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsWCQDGCS %>% filter(Order.q == 1) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

ShanEstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")

# plot correlation
corrplot(ShanEstCor, method="circle")

# largest correlation
ind<-which(ShanEstCor==max(ShanEstCor),arr.ind = TRUE)
rownames(ShanEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.95) for unstructured data
hill1_map_WC_QDGCU95Ab <- hill1_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.95, data_type = "abundance") 
plot(hill1_map_WC_QDGCU95Ab, title = "Shannon diversity - unstructured data (0.95 coverage)")
```

Compare estimates

```{r}
hill1_map_WC_QDGCU95Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot shannon diversity from unstructured data (b3gbi (abundance) - coverage 0.95) and shannon diversity from iNEXT (incidence - 0.995) from structured data
hill1EstsWCQDGCS %>% 
   inner_join(hill1_map_WC_QDGCU95Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon diversity - structured data (iNEXT (incidence) - 0.945)",
       y = "Shannon diversity - unstructured (b3gbi (abundance) - 0.95)")
```

# Hill-Simpson Diversity (only possible for QDGC) - based on incidence (structured) and abundance (unstructured)

Unstructured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_WC_QDGCUAb <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill2_map_WC_QDGCUAb, title = "Simpson Diversity - unstructured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_WC_QDGCSAb <- hill2_map(WCStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill2_map_WC_QDGCSAb, title = "Simpson Diversity - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill2_map_WC_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill2_map_WC_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_WC_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Simpson Diversity for structured data estimated uising b3gbi (abundance) and Simpson Diversity from iNEXT for structured data ()incidence
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT (incidence) - 0.945)",
       y = "Simpson Diversity - structured data (b3gbi (abundance) -0.95)")
```


```{r}
# Plot Simpson Diversity for unstructured data estimated using b3gbi (aundance) and Simpson Diversity from iNEXT from structured data (incidence)
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT (incidence) - 0.945)",
       y = "Simpson Diversity - unstructured data (b3gbi (abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill2_map_WC_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate simpson diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill2 <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance",  coverage = i)
  hill2 <- hill2$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill2[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate simpson diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsWCQDGCS %>% filter(Order.q == 2) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
StrucEstsSub<-StrucEsts %>% filter (QDGCcode %in% UnstrucEsts$QDGCcode)
UnstrucEstsSub<-UnstrucEsts %>% filter (QDGCcode %in% StrucEstsSub$QDGCcode)

SimpEstCor<-cor(UnstrucEstsSub[2:ncol(UnstrucEstsSub)], StrucEstsSub[2], method = "pearson")

# plot correlation
corrplot(SimpEstCor, method="circle")

# largest correlation
ind<-which(SimpEstCor==max(SimpEstCor),arr.ind = TRUE)
rownames(SimpEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.55) for unstructured data
hill2_map_WC_QDGCU55Ab <- hill2_map(WCunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.55, data_type = "abundance") 
plot(hill2_map_WC_QDGCU55Ab, title = "Simpson diversity - unstructured data (0.55 coverage)")
```

Compare estimates

```{r}
hill2_map_WC_QDGCU55Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot simpson diversity from unstructured data (b3gbi (abundance) - coverage 0.55) and simpson diversity from iNEXT (incidence - 0.945) from structured data
hill2EstsWCQDGCS %>% 
   inner_join(hill2_map_WC_QDGCU55Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson diversity - structured data (iNEXT (incidence) - 0.945)",
       y = "Simpson diversity - unstructured data (b3gbi (abundance) - 0.55)")
```