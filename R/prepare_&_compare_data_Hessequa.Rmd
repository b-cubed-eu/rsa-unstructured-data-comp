---
title: "Preparation and comparison of structured (SABAP2) and unstructured data for Hessequa Atlas Area"
author: "Katelyn Faulkner"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
# Load packages
library(tidyverse)    # Data wrangling and visualisation
library(here)         # Relative paths
library(sf)           # Work with spatial data
library(rgbif)        # To request occurrence cubes
library(gcube)        # To create a bespoke cube 
library(iNEXT)        # To calculate sample coverage
library(b3gbi)        # To calculate indicators
library(ggpubr)       # Correlations
library(RColorBrewer) # Colour palette
library(corrplot)     # Correlation plots
```

# Goal

Load and prepare structured data of the Hessequa systematic atlasing subproject of the “Southern African Bird Atlas Project 2” (SABAP2).

Load and prepare unstructured data from GBIF.

Make corrections for sample effort and compare the data.

SABAP2 data are collected at a pentad resolution (5min x 5min).

The data are prepared both at a pentad resolution, and at quarter degree grid cell resolution. 9 pentads fit into one quarter degree grid cell (15 min x 15 min)

The period 2015-2023 is of interest. The Hessequa systematic atlasing subproject began late 2014, and as it takes some time for data to flow into GBIF, it is useful to include data up until one full year has passed (e.g., end of 2023 if analysing data in 2025)

# Load data

## Structured data

### Sampling framework

**SABAP2 - Southern African Bird Atlas Project 2 - sampling framework** is downloaded as a geoJSON file from https://sabap2.birdmap.africa/coverage/group/Hssq1.

Follow the instructions on the website to download the file, then save it as a shapefile and store under *./data/raw*.

We read in the dataset.

```{r}
# Data path and create directory if necessary
data_path <- here::here("data", "raw")
dir.create(data_path, showWarnings = FALSE, recursive = TRUE)
```

```{r}
# Read SABAP2 Hessequa atlas area pentad grid (5min x 5 min/ 8.2 km x 8.2 km)
HAASFraw <- read_sf(file.path(data_path, "Hessequa_sampling_framework", "Hessequa_sampling_framework.shp"))

# Explore dataframe
glimpse(HAASFraw)
```

### Occurrence data

Occurrence data was downloaded from GBIF.org.
Unzip and store folder under *./data/raw*.

The following filters were used/considered:
- Occurrence Status IS Present
- Dataset IS 'Southern African Bird Atlas Project 2'
- Year IS '2015-2023'
- Administrative areas (gadm.org) IS 'Western Cape - ZAF.9_1'
- Basis of record IS NOT 'FOSSIL_SPECIMEN' OR 'LIVING_SPECIMEN'
- Issues and Flags NOT = 'Zero coordinate' OR 'Coordinate out of range' OR 'Coordinate invalid' OR 'country coordinate mismatch' OR 'Taxon match higherrank' (i.e., speciesKey IS NOT NULL)
- Location IS 'Including coordinates' (i.e., decimalLatitude IS NOT NULL
AND decimalLongitude IS NOT NULL)

Note that some of the above filters were not relevant (e.g., no fossil specimen records)

Therefore, the SABAP2 dataset was filtered so that only data from the Western Cape between 2015-2023, with speciesKey information was downloaded.

Note these data were not obtained as a cube through rgbif, as some manipulation is required to remove adhoc records that is not possible with the filters available.

**SABAP2 - Southern African Bird Atlas Project 2**: 0031129-250811113504898.zip

GBIF.org (22 August 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.fa9thf

We read in the dataset.

```{r}
# Read SABAP2 data as tab delimited
SABAP2WCraw <- read_delim(file.path(data_path,
                                     "0031129-250811113504898",
                                     "occurrence.txt"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(SABAP2WCraw)
```


## Unstructured data 

### Download cube (qdgc per year)

Retrieved a species occurrence cube using rgbif. 
The occurrence cube is at QDGC scale per year.
To account for sampling bias, the specification recommends including an occurrence count for a higher taxon, typically the family.

The query excluded SABAP2 data

Data for the Western Cape were selected (level1Gid = 'ZAF.9_1')

27 000 m (27km) used as minimum for coordinate uncertainty as smaller than one edge of the grid used (would be 1000 m for a 1 km grid).

Note, personal details (usernname, password and email address) have been removed from script below

```{r, eval = FALSE}
# yearly cube at qdgc resolution
occ_download_sql(user = "", pwd = "", email = "", "SELECT \"year\", GBIF_EQDGCode(2, decimalLatitude, decimalLongitude, COALESCE(coordinateUncertaintyInMeters, 27000)) AS qdgcCode,speciesKey,species, \"order\", family, genus, COUNT(*) AS n,MIN(COALESCE(coordinateUncertaintyInMeters, 27000)) AS minCoordinateUncertaintyInMeters, IF(ISNULL(\"order\"), NULL, SUM(COUNT(*)) OVER (PARTITION BY \"order\")) AS orderCount, IF(ISNULL(family), NULL, SUM(COUNT(*)) OVER (PARTITION BY family)) AS familyCount, IF(ISNULL(genus), NULL, SUM(COUNT(*)) OVER (PARTITION BY genus)) AS genusCount FROM occurrence WHERE class = 'Aves' AND occurrenceStatus = 'PRESENT'AND (coordinateUncertaintyInMeters <= 27000 OR coordinateUncertaintyInMeters IS NULL) AND NOT occurrence.basisofrecord IN ('FOSSIL_SPECIMEN', 'LIVING_SPECIMEN') AND NOT ARRAY_CONTAINS(issue, 'ZERO_COORDINATE') AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_OUT_OF_RANGE') AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_INVALID') AND NOT ARRAY_CONTAINS(issue, 'COUNTRY_COORDINATE_MISMATCH') AND level1Gid = 'ZAF.9_1' AND \"year\" >= 2015 AND \"year\" <= 2023 AND speciesKey IS NOT NULL AND decimalLatitude IS NOT NULL AND decimalLongitude IS NOT NULL AND collectionCode != 'SABAP2' GROUP BY \"year\", qdgcCode, speciesKey, \"order\", family, genus, species ORDER BY \"year\" ASC, qdgcCode ASC, speciesKey ASC")
```

The data are downloaded and stored under *./data/raw*.

**Unstructured bird data Western Cape QGDC cube**: 0002416-251025141854904.zip

GBIF.org (27 October 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.nqf9x5

We read in the dataset.

```{r}
# Read in datacube from CSV
birdcubeWCYearQDGC <- read_delim(file.path(data_path,
                                     "0002416-251025141854904", "0002416-251025141854904.csv"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(birdcubeWCYearQDGC)
```

### Download occurrence data and create cube (pentad per year)

Cube at pentad resolution not available through rgbif. Therefore, retrieved species occurrence data using rgbif, and created a yearly cube at pentad resolution using gcube.

Occurrence data is downloaded from GBIF.org. Unzip and store folders under *./data/raw*.

The query had the same specifications as the cube query, except 8 000 m (8km) was used as minimum for coordinate uncertainty, as smaller than one edge of the grid used (would be 1000 m for a 1 km grid).

Note, personal details (usernname, password and email address) have been removed from script below

```{r}
occ_download(user = "", pwd = "", email = "", pred("taxonKey", 212), 
             pred("occurrenceStatus", "PRESENT"), 
             pred_or(pred_lte("coordinateUncertaintyInMeters", 8000),pred_isnull("coordinateUncertaintyInMeters")), 
             pred("gadm", "ZAF.9_1"), 
             pred_and(pred_gte("year","2015"), pred_lte("year", "2023")), 
             pred_notnull("speciesKey"), 
             pred_notnull("decimalLatitude"), 
             pred_notnull("decimalLongitude"), 
             pred_not(pred_in("collectionCode", "SABAP2")), 
             pred_not(pred_in("basisOfRecord", c("FOSSIL_SPECIMEN", "LIVING_SPECIMEN"))),
             pred_not(pred_in("issue", c("ZERO_COORDINATE", "COORDINATE_OUT_OF_RANGE", "COORDINATE_INVALID", "COUNTRY_COORDINATE_MISMATCH"))))
```

**Unstructured bird data Western Cape**: 0002426-251025141854904.zip

GBIF.org (27 October 2025) GBIF Occurrence Download https://doi.org/10.15468/dl.jxzwn4

We read in the dataset.

```{r}
# Read unstructured data as tab delimited
birdsWCraw<- read_delim(file.path(data_path,
                                     "0002426-251025141854904",
                                     "occurrence.txt"),
                   delim = "\t",
                   show_col_types = FALSE)

# Explore dataframe
glimpse(birdsWCraw)
```

Create a cube from downloaded occurrence data

```{r}
# select columns required
birdsWC<- birdsWCraw %>% select (c('year', 'month', 'order', 'family', 'genus', 'speciesKey', 'species', 'decimalLatitude', 'decimalLongitude', 'coordinateUncertaintyInMeters'))
```

```{r}
# calculate the pentad based on co-ordinates and create a pentad column
# Note a function has also been written to do this, but is not implemented here

birdsWC<-birdsWC %>% separate(decimalLatitude, c("degreesLat", "otherLat"), "\\.", remove = FALSE)%>%
  mutate(otherLat = (as.numeric(paste0("0.", otherLat)))*60) %>%
  mutate(otherLat = sprintf('%02d', plyr::round_any(otherLat, 5, floor))) %>%
mutate(degreesLat = gsub("-","",degreesLat))  %>% 
  unite("pentadLat", degreesLat:otherLat, remove = TRUE, sep = "")
 
birdsWC<-birdsWC %>% separate(decimalLongitude, c("degreesLong", "otherLong"), "\\.", remove = FALSE)%>%
  mutate(otherLong = (as.numeric(paste0("0.", otherLong)))*60) %>%
  mutate(otherLong = sprintf('%02d', (plyr::round_any(otherLong, 5, floor)))) %>%
mutate(degreesLong = gsub("-","",degreesLong))  %>% 
  unite("pentadLong", degreesLong:otherLong, remove = TRUE, sep = "")  

birdsWC<-birdsWC %>% unite("pentad", c(pentadLat,pentadLong), sep = "_", remove = TRUE)
```

Prepare data for gcube

```{r}
# add time point for each observation based on year
birdsWC<- birdsWC %>% mutate (time_point = case_when(
  year == 2015  ~ 1,
  year == 2016  ~ 2,
  year == 2017  ~ 3,
  year == 2018  ~ 4,
  year == 2019  ~ 5,
  year == 2020  ~ 6,
  year == 2021  ~ 7,
  year == 2022  ~ 8,
  year == 2023  ~ 9,
  ))

Hpentads<-unique(HAASFraw$pentad) # pentads in Hessequa atlas area

# subset to only include records from Hessequa atlas area, remove NA speciesKey, Assign NA coordinateUncertaintyInMeters to '8000m'
birdsHAA <- birdsWC %>% filter(birdsWC$pentad %in% Hpentads) %>%
  drop_na(speciesKey) %>% replace_na(list(coordinateUncertaintyInMeters = 8000))
```

```{r}
# create sf object
birdsHAAsf <- st_as_sf(x = birdsHAA,                         
               coords = c('decimalLongitude', 'decimalLatitude'), crs = st_crs(HAASFraw))
```

```{r}
# reproject to a flat co-ordinate reference system
birdsHAAsfreproj <- st_transform(birdsHAAsf, crs = "EPSG:2049") # EPSG:2049 is ideal for Hessequa Atlas Area
  
HAASFrawReproj<-st_transform(HAASFraw, crs = "EPSG:2049")
```

Create cube

```{r}
# Get species
taxa <- sort(unique(birdsHAAsfreproj$species))

# Create empty list
occurrence_cube_list <- vector(mode = "list", length = length(taxa))

# Loop over species
for (i in seq_along(taxa)) {
  # Get species
  taxon <- taxa[i]
  
  # Filter data
  taxon_data <- birdsHAAsfreproj %>%
    filter(taxon == species)
  
  # Perform grid designation
  taxon_cube <- grid_designation(
    observations = taxon_data,
    grid = HAASFrawReproj, seed = 123
  )
  
  # Add species column
  taxon_cube$species <- taxon
  
  # Add species cube to list
  occurrence_cube_list[[i]] <- taxon_cube
}

# Combine species cubes
occurrence_cube_full <- bind_rows(occurrence_cube_list)
```

structure cube in the same way as rgbif

```{r}
MissDeats<-birdsHAAsfreproj %>%  st_drop_geometry() %>%
  select(order:species) %>%
  distinct()

birdcubeHAAYearPentad <- occurrence_cube_full %>%
  st_drop_geometry() %>%
  filter(n != 0) %>% mutate (year = case_when(
  time_point == 1 ~ 2015,
  time_point == 2  ~ 2016,
  time_point == 3  ~ 2017,
  time_point == 4  ~ 2018,
  time_point == 5  ~ 2019,
  time_point == 6 ~ 2020,
  time_point == 7  ~ 2021,
  time_point == 8  ~ 2022,
  time_point == 9  ~ 2023,
  )) %>% select(n:pentad, species:year) %>% left_join(MissDeats)%>% rename(mincoordinateuncertaintyinmeters = min_coord_uncertainty)

fam<-birdcubeHAAYearPentad %>% group_by(pentad, family) %>% summarise(familycount = sum(n))

ord<-birdcubeHAAYearPentad %>% group_by(pentad, order) %>% summarise(ordercount = sum(n))

gen<-birdcubeHAAYearPentad %>% group_by(pentad, genus) %>% summarise(genuscount = sum(n))

birdcubeHAAYearPentad<-birdcubeHAAYearPentad %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

# Subset datasets 

Select Hessequa Atlas Area grid cells, data falling into correct time period (2015-2023), and where full protocol was used for surveys (i.e., adhoc records in SABAP2 are removed). From cubes remove records with a minimum co-ordinate uncertainty of > 8 km for pentads (records with a minimum co-ordinate uncertainty of > 27 km were removed during the production of the qdgc cube)

## SABAP2 data for Western Cape

Select cells that fall into Hessequa Atlas Area

Select records from events where full sampling protocol was followed (i.e., adhoc sampling removed)

Create a column called 'pentad'

Add a column with QDGC information

```{r}
# subset data to include only full protocol data
SABAP2WC<-SABAP2WCraw %>% filter(grepl("full", SABAP2WCraw$occurrenceID, fixed = TRUE))

# subset data to only include records from Hessequa atlas area
Hpentads<-unique(HAASFraw$pentad) # pentads in Hessequa atlas area
SABAP2HAA <- SABAP2WC %>% filter(SABAP2WC$verbatimLocality %in% Hpentads)

# create new column called pentad
SABAP2HAA <- SABAP2HAA  %>%
  mutate(pentad = verbatimLocality)

# create new column called qdgccode
SABAP2HAA <- SABAP2HAA  %>%
  separate(locationRemarks, into = c('Long', 'Lat', 'Code'), sep = c(2,4), remove = FALSE) %>%
mutate(Long = paste0("S", Long))%>%
  mutate(Lat = paste0("E0", Lat))%>%
  unite(qdgccode, c(Lat,Long,Code), remove = TRUE, sep = "")

# remove duplicate cards for the same species & remove card '3355_2045_013624_20201128'which is causing issues and is not SABAP2 dataset online

SABAP2HAA<-SABAP2HAA %>% distinct(species, fieldNotes, .keep_all = TRUE) %>% filter(fieldNotes != "3355_2045_013624_20201128")
```

## Sampling framework data for Hessequa Atlas Area

Select data from years between 2015 and 2023

Calculate number of full protocol sampling events

Add a column with QDGC information. Need to use a function get_qdgcCode() to convert decimal degree co-ordinates to QDGC

```{r}
# Function to get quarter degree grid cell codes from decimal co-ordinates

get_qdgcCode <- function(lat, lon) {
  dirLon<-lon < 0 # true if longitude is negative
  dirLat<-lat < 0 # true if latitude is negative
  
  DegLonCod<-ifelse(dirLon == TRUE, "W", "E") # assign east/west
  DegLatCod<-ifelse(dirLat == TRUE, "S", "N") # assign north/south
  
  DegLon <- ifelse(dirLon == TRUE, -1*ceiling(lon), floor(lon)) # extract the integer from longitude (needs to be positive)
  DegLat <- ifelse(dirLat == TRUE, -1*ceiling(lat), floor(lat)) # extract the integer from latitude (needs to be positive)
  
  declat<-as.numeric(paste0("0.", unlist(stringr::str_split(lat, "\\."))[2])) # extract the fractional part of latitude
  declon<-as.numeric(paste0("0.", unlist(stringr::str_split(lon, "\\."))[2])) # extract the fractional part of longitude
  
  # Determine first code based on fractional portions
  
  DegCode<-ifelse(declat < 0.5 & declon < 0.5, "A", 
         ifelse(declat < 0.5 & declon > 0.5, "B",
         ifelse(declat > 0.5 & declon < 0.5, "C", "D")))
  
  # Determine second code based on fractional portions
  
  DegCode<-ifelse(declat < 0.5 & declon < 0.5, "A", 
                  ifelse(declat < 0.5 & declon > 0.5, "B",
                         ifelse(declat > 0.5 & declon < 0.5, "C", "D")))
 
  
  if(DegCode == "A"){
    QDegCode<-ifelse(declat < 0.25 & declon < 0.25, "A", 
           ifelse(declat < 0.25 & declon > 0.25, "B",
                  ifelse(declat > 0.25 & declon < 0.25, "C", "D")))
  }
  
 if(DegCode == "B"){
   QDegCode<-ifelse(declat < 0.25 & declon < 0.75, "A", 
           ifelse(declat < 0.25 & declon > 0.75, "B",
                  ifelse(declat > 0.25 & declon < 0.75, "C", "D")))
  }
  
  if(DegCode == "C"){
    QDegCode<-ifelse(declat < 0.75 & declon < 0.25, "A", 
           ifelse(declat < 0.75 & declon > 0.25, "B",
                  ifelse(declat > 0.75 & declon < 0.25, "C", "D")))
  }
  
  if(DegCode == "D"){
    QDegCode<-ifelse(declat < 0.75 & declon < 0.75, "A", 
           ifelse(declat < 0.75 & declon > 0.75, "B",
                  ifelse(declat > 0.75 & declon < 0.75, "C", "D")))
  }
  
  # Construct QDGC string
  
  paste0(DegLonCod, '0', DegLon, DegLatCod, DegLat, DegCode, QDegCode)
  
  }
```

```{r}
# subset data to include years between 2015 and 2023
HAASF<-HAASFraw %>% select(!(c('full proto':'2014','2024', '2025')))

# calculate number of full sampling protocols per year
HAASF<-HAASF %>%
  rowwise() %>%
  mutate(fullprotocol = sum(c_across('2015':'2023')))

# get co-ordinates of points in each pentad
HAASFcentroids <- st_centroid(HAASF)
HAASFcoords<-st_coordinates(HAASFcentroids)

# use get_qdgcCode function to get qdgc codes from co-ordinates
HAASF$qdgccode<-apply(HAASFcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

## Bird occurrence cube for Western Cape at QDGC

Select data from QDGC that include Hessequa Atlas Area

```{r}
# subset cube to only include QDGC from Hessequa atlas area 

HAAQDGC<-unique(HAASF$qdgccode) # QDGC in Hessequa atlas area

birdcubeHAAYearQDGC <- birdcubeWCYearQDGC %>% filter(birdcubeWCYearQDGC$qdgccode %in% HAAQDGC)
```

## Bird occurrence cube for Western Cape at pentads

Exclude data that have mincoordinateuncertaintyinmeters > 8 km

```{r}
# Subset data to only include records with min co-ordinate uncertainty of <= 8 km
birdcubeHAAYearPentad <- birdcubeHAAYearPentad %>% filter(mincoordinateuncertaintyinmeters <=8000)
```

# Create SABAP2 cubes with sample data

## SABAP2 QDGC cube

```{r}
# filter out na species, classify commonness, Group by species, year and qdgccode
SABAP2HAAQDGCYear <-SABAP2HAA %>% filter(!is.na(species)) %>%
  group_by(species) %>%
  mutate(n_obs = n()) %>%
  ungroup() %>%
  mutate(category = cut(n_obs,
                        breaks = c(0, 10, 100, 1000, 10000, +Inf),
                        labels = c("Very rare", "Rare", "Common",
                                   "Very common", "Extremely common"),
                        right = FALSE)) %>%
  group_by(species, family, order, genus, year , speciesKey, qdgccode, category) %>%
  summarise(n = n())

# counts for genera, family, order
fam<-SABAP2HAAQDGCYear %>% group_by(qdgccode, family) %>% summarise(familycount = sum(n))

ord<-SABAP2HAAQDGCYear %>% group_by(qdgccode, order) %>% summarise(ordercount = sum(n))

gen<-SABAP2HAAQDGCYear %>% group_by(qdgccode, genus) %>% summarise(genuscount = sum(n))

SABAP2HAAQDGCYear<-SABAP2HAAQDGCYear %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

```{r}
# Sampling data: drop geometry and get number of samples per QDGC
QDGCSamp<-HAASF %>% st_drop_geometry() %>% 
group_by(qdgccode) %>%
            summarise_at(vars('2015':'2023', 'fullprotocol'), sum)

# make a long-form
QDGCSampLong <-  QDGCSamp %>%  pivot_longer(cols = "2015":"2023", names_to = "year", values_to = "totalYear", names_transform = list(year = as.integer))

# join datasets
SABAP2HAAQDGCYearSamp<-SABAP2HAAQDGCYear %>% left_join(QDGCSampLong, by = join_by(qdgccode, year)) %>% ungroup()

# check that samples and no records make sense
test<-SABAP2HAAQDGCYearSamp$n<=SABAP2HAAQDGCYearSamp$totalYear
tmp<-which(test == FALSE)
issues<-alldat[tmp,]
```

## SABAP2 QDGC for iNEXT

```{r}
# Group by species, and QDGC, and reformat for iNEXT
SABAP2HAAQDGCWide <-SABAP2HAA %>% 
  group_by(species, speciesKey, qdgccode) %>%
  summarise(n = n()) %>% 
  ungroup() %>%
  pivot_wider(names_from = qdgccode, values_from = n, values_fill = 0) %>%
  select(!(species:speciesKey))

# make a similar wide dataset with full protocol counts
HAAQDGCSamp<-QDGCSamp %>% select(fullprotocol, qdgccode) %>% unique() %>%  
  pivot_wider(names_from = qdgccode, values_from = fullprotocol)

# bind datasets together and make into list
HAAQDGCincid<-rbind(HAAQDGCSamp, SABAP2HAAQDGCWide) %>% as.list()
```

### Calculate sample coverage for each cell

```{r}
# run iNEXT
HAAQDGCSC <- iNEXT(HAAQDGCincid, q=0, datatype="incidence_freq")

# Visualise and get values for range of number of surveys
hist(HAAQDGCSC$DataInfo$T) # histogram of number of surveys
range(HAAQDGCSC$DataInfo$T) # range of values

# Visualise and get values sample coverage
hist(HAAQDGCSC$DataInfo$SC)# histogram of sample coverage for the grid cells
range(HAAQDGCSC$DataInfo$SC) # range of values
summary(HAAQDGCSC$DataInfo$SC) # summary of sample coverage
```

## SABAP2 pentad cube

```{r}
# filter out na species, classify commonness, Group by species, year and qdgccode
SABAP2HAAPenYear <-SABAP2HAA %>% filter(!is.na(species)) %>%
  group_by(species) %>%
  mutate(n_obs = n()) %>%
  ungroup() %>%
  mutate(category = cut(n_obs,
                        breaks = c(0, 10, 100, 1000, 10000, +Inf),
                        labels = c("Very rare", "Rare", "Common",
                                   "Very common", "Extremely common"),
                        right = FALSE)) %>%
  group_by(species, family, order, genus, year, speciesKey, pentad, category) %>%
  summarise(n = n())

# counts for genera, family, order
fam<-SABAP2HAAPenYear %>% group_by(pentad, family) %>% summarise(familycount = sum(n))

ord<-SABAP2HAAPenYear %>% group_by(pentad, order) %>% summarise(ordercount = sum(n))

gen<-SABAP2HAAPenYear %>% group_by(pentad, genus) %>% summarise(genuscount = sum(n))

SABAP2HAAPenYear<-SABAP2HAAPenYear %>% inner_join(fam) %>% inner_join(ord) %>% inner_join(gen)
```

```{r}
# Sampling data: drop geometry and get number of samples per pentad
PenSamp<-HAASF %>% st_drop_geometry() %>% 
group_by(pentad) %>%
            summarise_at(vars('2015':'2023', 'fullprotocol'), sum)

# make a long-form
PenSampLong <-  PenSamp %>%  pivot_longer(cols = "2015":"2023", names_to = "year", values_to = "totalYear", names_transform = list(year = as.integer))

# join datasets
SABAP2HAAPenYearSamp<-SABAP2HAAPenYear %>% left_join(PenSampLong, by = join_by(pentad, year))  %>% ungroup()

# check that samples and no records make sense
test<-SABAP2HAAPenYearSamp$n<=SABAP2HAAPenYearSamp$totalYear
tmp<-which(test == FALSE)
```

## SABAP2 pentads for iNEXT

```{r}
# Group by species, and pentad, and reformat for iNEXT
SABAP2HAAPenWide <-SABAP2HAA %>% 
  group_by(species, speciesKey, pentad) %>%
  summarise(n = n()) %>% 
  ungroup() %>%
  pivot_wider(names_from = pentad, values_from = n, values_fill = 0) %>%
  select(!(species:speciesKey))

# make a similar wide dataset with full protocol counts
HAAPenSamp<-PenSamp %>% select(fullprotocol, pentad) %>% unique() %>%  
  pivot_wider(names_from = pentad, values_from = fullprotocol)

# remove cells not in surveys
HAAPenSamp<- HAAPenSamp %>%  select(matches(names(SABAP2HAAPenWide)))

# bind datasets together and make into list
HAAPenincid<-rbind(HAAPenSamp, SABAP2HAAPenWide) %>% as.list()
```

### Calculate sample coverage for each cell

```{r}
# run iNEXT
HAAPenSC <- iNEXT(HAAPenincid, q=0, datatype="incidence_freq")

# Visualise and get values for range of number of surveys
hist(HAAPenSC$DataInfo$T) # histogram of number of surveys
range(HAAPenSC$DataInfo$T) # range of values

# Visualise and get values sample coverage
hist(HAAPenSC$DataInfo$SC)# histogram of sample coverage for the grid cells
range(HAAPenSC$DataInfo$SC) # range of values
summary(HAAQDGCSC$DataInfo$SC) # summary of sample coverag
```

# Write data to file

```{r}
out_path <- here::here("data", "interim")
dir.create(out_path, showWarnings = FALSE, recursive = TRUE)

# Structured data at QDGC scale
write.csv(SABAP2HAAQDGCYearSamp, file.path(out_path, "SABAP2_QDGC_HAA_data.csv"), row.names = F)

# Structured data at QDGC scale for iNEXT
saveRDS(HAAQDGCincid, file.path(out_path, "SABAP2_QDGC_HAA_iNEXT.rds"))

# Unstructured data at QDGC scale
write.csv(birdcubeHAAYearQDGC, file.path(out_path, "Unstruc_QDGC_HAA_data.csv"), row.names = F)

# Structured data at pentad scale
write.csv(SABAP2HAAPenYearSamp, file.path(out_path, "SABAP2_Pentad_HAA_data.csv"), row.names = F)

# Structured data at pentad scale for iNEXT
saveRDS(HAAPenincid, file.path(out_path, "SABAP2_Pentad_HAA_iNEXT.rds"))

# Unstructured data at pentad scale
write.csv(birdcubeHAAYearPentad, file.path(out_path, "Unstruc_Pentad_HAA_data.csv"), row.names = F)
```


# Basic data exploration

## Structured data

### Number of surveys per year

Quarter degree grid cells

```{r}
SABAP2HAAQDGCYearSamp %>% select(year, qdgccode, totalYear) %>% unique() %>%  group_by(year) %>% summarise(n = sum(totalYear)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of surveys")
```

Pentads

```{r}
SABAP2HAAPenYearSamp %>% select(year, pentad, totalYear) %>% unique() %>%  group_by(year) %>% summarise(n = sum(totalYear)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of surveys")
```

### Number of observations per year

Quarter degree grid cells

```{r}
SABAP2HAAQDGCYearSamp %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

Pentads

```{r}
SABAP2HAAPenYearSamp %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

### Number of surveys per grid cell

Quarter degree grid cells

```{r}
SABAP2HAAQDGCYearSamp %>% select(qdgccode, fullprotocol) %>%unique() %>%
  group_by(qdgccode) %>%
    summarise(n = sum(fullprotocol)) %>%
  ggplot(aes(x = n)) +
  geom_histogram(fill = "#D95F02", color = "black") +
  labs(x = "Number of surveys",
       y = "Number of quarter-degree grid cells")
```

Pentads

```{r}
SABAP2HAAPenYearSamp %>% select(pentad, fullprotocol) %>%unique() %>%
  group_by(pentad) %>%
    summarise(n = sum(fullprotocol)) %>%
  ggplot(aes(x = n)) +
  geom_histogram(fill = "#D95F02", color = "black") +
  labs(x = "Number of surveys",
       y = "Number of pentad grid cells")
```

## Unstructured data

### Number of observations per year

Quarter degree grid cells

```{r}
birdcubeHAAYearQDGC %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

Pentads

```{r}
birdcubeHAAYearPentad %>% group_by(year) %>%
    summarise(n = sum(n)) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = "#1B9E77", color = "black") +
  labs(x = "Year",
       y = "Number of observations")
```

# Calculation of metrics and comparison

```{r}
# Create a custom color scale
library(RColorBrewer)
myColors <- brewer.pal(5, "Dark2")
names(myColors) <- c("Very rare", "Rare", "Common",
                     "Very common", "Extremely common")
colScale <- scale_color_manual(name = "Category",
                                values = myColors)
fillScale <- scale_fill_manual(name = "Category",
                                values = myColors)
```

## Range

### QDGC

```{r}
# species recorded in sabap2
studied_spec <- unique(SABAP2HAAQDGCYearSamp$species) %>%
  na.omit()
```

```{r}
# function to compare ranges
range_comp <- function(sel_species, period = 2015:2023,
                       dataset1 = SABAP2HAAQDGCYearSamp,
                       dataset2 = birdcubeHAAYearQDGC) {

  # We filter both datasets for the species and period of interest
  # and group them by QDGC
  set_sabap2 <- dataset1 %>%
      filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$qdgccode) %>%
    summarise(n = n()) # no observations rather than no individuals

  set_cube <- dataset2 %>%
    filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$qdgccode) %>%
    summarise(n = sum(.data$n))

  total_sabap2 <- length(set_sabap2$qdgccode)
  perc_sabap2 <- (total_sabap2 / 15) * 100 # have taken the value to be total number of grid cells in area of interest
  
  total_cube <- length(set_cube$qdgccode)
  perc_cube <- (total_cube / 15) * 100 # have taken the value to be total number of grid cells in area of interest

  overlap_all_sabap2_cube <- length(
    which(set_cube$qdgccode %in% unique(dataset1$qdgccode))
    )
  perc_overlap_all <- (overlap_all_sabap2_cube / 15) * 100 # have taken the value to be total number of grid cells in the sabap2 data

  total_overlap <- length(which(set_cube$qdgccode %in% set_sabap2$qdgccode))
  perc <- (total_overlap / total_sabap2) * 100 

  list(total_sabap2, perc_sabap2,
       total_cube, perc_cube,
       overlap_all_sabap2_cube, perc_overlap_all,
       total_overlap, perc)
}
```

```{r}
# run function
comp_range_data <- as.data.frame(studied_spec)
comp_range_data$sabap2_squares <- NA
comp_range_data$perc_sabap2_total_sabap2 <- NA
comp_range_data$cube_squares <- NA
comp_range_data$perc_cube_total_cube <- NA
comp_range_data$overlap_birdcube_total_sabap2 <- NA
comp_range_data$perc_birdcube_total_sabap2 <- NA
comp_range_data$overlap_birdcube_spec_sabap2 <- NA
comp_range_data$percentage_birdcube_spec_sabap2 <- NA

for (i in studied_spec){
  test <- range_comp(i, period = 2015:2023)
  
  comp_range_data[comp_range_data$studied_spec == i, 2] <- test[1]
  comp_range_data[comp_range_data$studied_spec == i, 3] <- test[2]
  comp_range_data[comp_range_data$studied_spec == i, 4] <- test[3]
  comp_range_data[comp_range_data$studied_spec == i, 5] <- test[4]
  comp_range_data[comp_range_data$studied_spec == i, 6] <- test[5]
  comp_range_data[comp_range_data$studied_spec == i, 7] <- test[6]
  comp_range_data[comp_range_data$studied_spec == i, 8] <- test[7]
  comp_range_data[comp_range_data$studied_spec == i, 9] <- test[8]
}
```

```{r}
# summary of output
summary(comp_range_data)
```

Overall we see a range overlap of 65%

Range overlap

```{r}
# plot percentage range overlap
comp_range_data %>%
  inner_join(SABAP2HAAQDGCYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = percentage_birdcube_spec_sabap2,fill = category)) +
  geom_histogram() +
  fillScale +
  labs(x = "Percentage range overlap",
       y = "Number of species")
```

Range size

```{r}
# Plot number of grid cells in which species recorded in SABAP2 vs number of cells in which recorded in unstructured data
comp_range_data %>%
  inner_join(SABAP2HAAQDGCYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = sabap2_squares, y = cube_squares, color = category)) +
  geom_point() +
  colScale +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson")+
  labs(x = "Number of squares occupied\nby species in SABAP2 dataset",
       y = "Number of squares occupied\nby species in cube dataset")
```

## Pentad

```{r}
# species recorded in sabap2
studied_spec <- unique(SABAP2HAAPenYearSamp$species) %>%
  na.omit()
```

```{r}
# function to compare ranges
range_comp <- function(sel_species, period = 2015:2023,
                       dataset1 = SABAP2HAAPenYearSamp,
                       dataset2 = birdcubeHAAYearPentad) {

  # We filter both datasets for the species and period of interest
  # and group them by pentad
  set_sabap2 <- dataset1 %>%
      filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$pentad) %>%
    summarise(n = n()) # no observations rather than no individuals

  set_cube <- dataset2 %>%
    filter(.data$species %in% sel_species,
           .data$year %in% period) %>%
    group_by(.data$pentad) %>%
    summarise(n = sum(.data$n))

  total_sabap2 <- length(set_sabap2$pentad)
  perc_sabap2 <- (total_sabap2 / 77) * 100 # have taken the value to be total number of grid cells in area of interest
  
  total_cube <- length(set_cube$pentad)
  perc_cube <- (total_cube / 77) * 100 # have taken the value to be total number of grid cells in area of interest

  overlap_all_sabap2_cube <- length(
    which(set_cube$pentad %in% unique(dataset1$pentad))
    )
  perc_overlap_all <- (overlap_all_sabap2_cube / 77) * 100 # have taken the value to be total number of grid cells in the sabap2 data

  total_overlap <- length(which(set_cube$pentad %in% set_sabap2$pentad))
  perc <- (total_overlap / total_sabap2) * 100 

  list(total_sabap2, perc_sabap2,
       total_cube, perc_cube,
       overlap_all_sabap2_cube, perc_overlap_all,
       total_overlap, perc)
}
```

```{r}
# run function
comp_range_data <- as.data.frame(studied_spec)
comp_range_data$sabap2_squares <- NA
comp_range_data$perc_sabap2_total_sabap2 <- NA
comp_range_data$cube_squares <- NA
comp_range_data$perc_cube_total_cube <- NA
comp_range_data$overlap_birdcube_total_sabap2 <- NA
comp_range_data$perc_birdcube_total_sabap2 <- NA
comp_range_data$overlap_birdcube_spec_sabap2 <- NA
comp_range_data$percentage_birdcube_spec_sabap2 <- NA

for (i in studied_spec){
  test <- range_comp(i, period = 2015:2023)
  
  comp_range_data[comp_range_data$studied_spec == i, 2] <- test[1]
  comp_range_data[comp_range_data$studied_spec == i, 3] <- test[2]
  comp_range_data[comp_range_data$studied_spec == i, 4] <- test[3]
  comp_range_data[comp_range_data$studied_spec == i, 5] <- test[4]
  comp_range_data[comp_range_data$studied_spec == i, 6] <- test[5]
  comp_range_data[comp_range_data$studied_spec == i, 7] <- test[6]
  comp_range_data[comp_range_data$studied_spec == i, 8] <- test[7]
  comp_range_data[comp_range_data$studied_spec == i, 9] <- test[8]
}
```

```{r}
# summary of output
summary(comp_range_data)
```

Overall we see a range overlap of 24%

Range overlap

```{r}
# plot percentage range overlap
comp_range_data %>%
  inner_join(SABAP2HAAPenYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = percentage_birdcube_spec_sabap2,fill = category)) +
  geom_histogram() +
  fillScale +
  labs(x = "Percentage range overlap",
       y = "Number of species")
```

Range size

```{r}
# Plot number of grid cells in which species recorded in SABAP2 vs number of cells in which recorded in unstructured data
comp_range_data %>%
  inner_join(SABAP2HAAPenYearSamp %>% distinct(species, category),
            by = join_by(studied_spec == species)) %>%
  ggplot(aes(x = sabap2_squares, y = cube_squares, color = category)) +
  geom_point() +
  colScale +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson")+
  labs(x = "Number of squares occupied\nby species in SABAP2 dataset",
       y = "Number of squares occupied\nby species in cube dataset")
```

## b3gbi indicators

### Process cubes

Unstructured data at QDGC

```{r}
HAAunstrucQDGCproc <- process_cube(birdcubeHAAYearQDGC, grid_type = 'eqdgc', first_year = 2015, cols_year =  'year', cols_cellCode = 'qdgccode', cols_occurrences = 'n',  cols_minCoordinateUncertaintyInMeters	
= 'mincoordinateuncertaintyinmeters', cols_familyCount = 'familycount', cols_speciesKey = 'specieskey')
```

Structured data at QDGC

```{r}
HAAStrucQDGCproc <- process_cube(SABAP2HAAQDGCYearSamp, grid_type = 'eqdgc', first_year = 2015, cols_year =  'year', cols_cellCode = 'qdgccode', cols_occurrences = 'n', cols_speciesKey = 'speciesKey', cols_familyCount = 'familycount')
```

Unstructured data for pentads

```{r}
HAAunstrucPenproc <- process_cube(birdcubeHAAYearPentad, grid_type = 'custom', first_year = 2015, cols_year =  'year', cols_cellCode = 'pentad', cols_occurrences = 'n',  cols_minCoordinateUncertaintyInMeters 
= 'mincoordinateuncertaintyinmeters', cols_familyCount = 'familycount', cols_speciesKey = 'speciesKey')
```

Structured data for pentads

```{r}
HAAstrucPenproc <- process_cube(SABAP2HAAPenYearSamp, grid_type = 'custom', first_year = 2015, cols_year =  'year', cols_cellCode = 'pentad', cols_occurrences = 'n',  cols_familyCount = 'familycount', cols_speciesKey = 'speciesKey')
```

### Total occurrences

Unstructured data QDGC

```{r}
map_obs_HAA_QDGCU <- total_occ_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_HAA_QDGCU, title = "Number of records - unstructured data")
```

Structured data QDGC

```{r}
map_obs_HAA_QDGCS <- total_occ_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_HAA_QDGCS, title = "Number of records - structured data")
```

Compare

```{r}
# Plot number of records structured vs unstructured data
map_obs_HAA_QDGCS$data %>% st_drop_geometry() %>% 
   inner_join(map_obs_HAA_QDGCU$data,
            by = join_by(cellid)) %>%
  ggplot(aes(x = diversity_val.x, y = diversity_val.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records - structured data",
       y = "Number of records - unstructured data")
```

Unstructured data pentads - note not possible through b3gbi

```{r}
obs_HAA_PenU<-birdcubeHAAYearPentad %>% group_by(pentad) %>% summarise(Obs = sum(n))
```

Structured data pentads - note not possible through b3gbi

```{r}
obs_HAA_PenS<-SABAP2HAAPenYearSamp %>% group_by(pentad, fullprotocol) %>% summarise(Obs = sum(n)) %>% mutate(Obseff = Obs/fullprotocol)
```

Compare

```{r}
# Plot number of records structured vs unstructured data
obs_HAA_PenS %>% 
   inner_join(obs_HAA_PenU,
            by = join_by(pentad)) %>%
  ggplot(aes(x = Obs.x, y = Obs.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records - structured data",
       y = "Number of records - unstructured data")
```


### Total occurrences (structured data corrected for sample effort)

QDGC

```{r}
obs_HAA_QDGCSeff<-SABAP2HAAQDGCYearSamp %>% group_by(qdgccode, fullprotocol) %>% summarise(Obs = sum(n)) %>% mutate(Obseff = Obs/fullprotocol)
```

Compare - QDGC

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

map_obs_HAA_QDGCU$data$qdgccode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot number of records structured corrected for survey effort vs unstructured data
obs_HAA_QDGCSeff %>% 
   inner_join(map_obs_HAA_QDGCU$data,
            by = join_by(qdgccode)) %>%
  ggplot(aes(x = Obseff, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records/number of surveys - structured data",
       y = "Number of records - unstructured data")
```

Pentad

```{r}
# Plot number of records structured vs unstructured data
obs_HAA_PenS %>% 
   inner_join(obs_HAA_PenU,
            by = join_by(pentad)) %>%
  ggplot(aes(x = Obseff, y = Obs.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Number of records/number of surveys - structured data",
       y = "Number of records - unstructured data")
```

### Observed richness

Unstructured data QDGC

```{r}
map_obs_rich_HAA_QDGCU <- obs_richness_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_rich_HAA_QDGCU, title = "Observed Bird Species Richness - unstructured data")
```

Structured data QDGC

```{r}
map_obs_rich_HAA_QDGCS <- obs_richness_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium")
plot(map_obs_rich_HAA_QDGCS, title = "Observed Bird Species Richness - structured data")
```

Compare

```{r}
# Plot number observed richness structured vs unstructured data
map_obs_rich_HAA_QDGCS$data %>% st_drop_geometry() %>% 
   inner_join(map_obs_rich_HAA_QDGCU$data,
            by = join_by(cellid)) %>%
  ggplot(aes(x = diversity_val.x, y = diversity_val.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Observed richness - structured data",
       y = "Observed richness - unstructured data")
```

Unstructured data pentads (note not possible through b3gbi as a bespoke grid)

```{r}
obs_rich_HAA_PenU <- HAAunstrucPenproc$data %>% group_by(cellCode) %>%
              summarise(n_species = n_distinct(scientificName), .groups = "drop")
```

Structured data pentads (note not possible through b3gbi as a bespoke grid)

```{r}
obs_rich_HAA_PenS <- HAAstrucPenproc$data %>% group_by(cellCode) %>%
              summarise(n_species = n_distinct(scientificName), .groups = "drop")
```

Compare

```{r}
# Plot number observed richness structured vs unstructured data
obs_rich_HAA_PenS %>%  
   inner_join(obs_rich_HAA_PenU,
            by = join_by(cellCode)) %>%
  ggplot(aes(x = n_species.x, y = n_species.y)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Observed richness - structured data",
       y = "Observed richness - unstructured data")
```


### Estimated richness - based on incidence data (structured and unstructured)

Unstructured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_HAA_QDGCU <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence")) 
plot(hill0_map_HAA_QDGCU, title = "Estimated Bird Species Richness - unstructured data (0.95 coverage)")
```

Structured QDGC - b3gbi with default settings & assume_freq  = FALSE

```{r}
# with default settings (coverage 0.95) and assume_freq = FALSE
hill0_map_HAA_QDGCS <- hill0_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence")) 
plot(hill0_map_HAA_QDGCS, title = "Estimated Bird Species Richness - structured data (0.95 coverage)")
```

Structured QDGC - b3gbi with default settings & assume_freq  = TRUE

```{r}
# with default settings (coverage 0.95) and assume_freq = TRUE
hill0_map_HAA_QDGCSas <- hill0_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("incidence"), assume_freq = TRUE)

plot(hill0_map_HAA_QDGCSas, title = "Estimated Bird Species Richness - structured data (0.95 coverage)")
```


Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
inEXTestsHAAQDGCS<-estimateD(HAAQDGCincid, datatype="incidence_freq",
          base="coverage", level=NULL, conf=0.95) # If base="coverage" and level=NULL, then this function computes the diversity estimates for the minimum among the coverage values for samples extrapolated to double the size of the reference sample.

# note the level implemented is 0.995...

richEstsHAAQDGCS<-inEXTestsHAAQDGCS %>% filter(Order.q == 0)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_rich_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

map_obs_rich_HAA_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_HAA_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_HAA_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_HAA_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot observed richness from unstructured data and estimated richness from iNEXT from structured data
richEstsHAAQDGCS %>% 
   inner_join(map_obs_rich_HAA_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995)",
       y = "Observed richness - unstructured data (b3gbi)")
```

```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95) and estimated richness from iNEXT (0.995) for structured data (note assume_freq = FALSE in b3gbi)
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995)",
       y = "Estimated richness - structured data (b3gbi - 0.95)")
```

```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95) and estimated richness from iNEXT (0.995) for structured data (note assume_freq = TRUE in b3gbi)
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995)",
       y = "Estimated richness - structured data (b3gbi - 0.95)")
```


```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.95) and estimated richness from iNEXT for structured data
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995)",
       y = "Estimated richness - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- map_obs_rich_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate richness for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill0 <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium",  coverage = i, data_type = "incidence") 
  hill0 <- hill0$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill0[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate richness for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-richEstsHAAQDGCS %>% filter(Order.q == 0) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
EstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(EstCor, method="circle")

# largest correlation
ind<-which(EstCor==max(EstCor),arr.ind = TRUE)
rownames(EstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.15) for unstructured data
hill0_map_HAA_QDGCU15 <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.15, data_type = "incidence") 
plot(hill0_map_HAA_QDGCU15, title = "Estimated Bird Species Richness - unstructured data (0.15 coverage)")
```

Compare estimates

```{r}
hill0_map_HAA_QDGCU15$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.15) and estimated richness from iNEXT (0.995) from structured data
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCU15$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995)",
       y = "Estimated richness - unstructured data (b3gbi - 0.15)")
```

Structured data for pentads - calculated with iNEXT (i.e., actual survey effort used)

```{r}
inEXTestsHAAPenS<-estimateD(HAAPenincid, datatype="incidence_freq",
          base="coverage", level=NULL, conf=0.95) # If base="coverage" and level=NULL, then this function computes the diversity estimates for the minimum among the coverage values for samples extrapolated to double the size of the reference sample.

# note the level implemented is 0.9805784

inEXTestsHAAPenS<-inEXTestsHAAPenS %>% filter(Order.q == 0)
```

Compare estimates

```{r}
# Plot observed richness from unstructured data and estimated richness from iNEXT from structured data
inEXTestsHAAPenS %>% 
   inner_join(obs_rich_HAA_PenU,
            by = join_by(Assemblage == cellCode)) %>%
  ggplot(aes(x = qD, y = n_species)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.98)",
       y = "Observed richness - unstructured data")
```

# Hill-Shannon Diversity (only possible for QDGC) - based on incidence data (structured and unstructured)

Unstructured data for QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill1_map_HAA_QDGCU <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill1_map_HAA_QDGCU, title = "Shannon Diversity - unstructured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi and assume_freq = F

```{r}
# with default settings (coverage 0.95)
hill1_map_HAA_QDGCS <- hill1_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill1_map_HAA_QDGCS, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi and assume_freq = T

```{r}
# with default settings (coverage 0.95)
hill1_map_HAA_QDGCSas <- hill1_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence", assume_freq = T) 
plot(hill1_map_HAA_QDGCSas, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
hill1EstsHAAQDGCS<-inEXTestsHAAQDGCS %>% filter(Order.q == 1)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill1_map_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill1_map_HAA_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_HAA_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_HAA_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data (with assume_freq =  F)
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.995)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95)")
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data (with assume_freq =  T)
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.995)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95)")
```



```{r}
# Plot Shannon Diversity for unstructured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.995)",
       y = "Shannon Diversity - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill1_map_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate shannon diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill1 <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence",  coverage = i)
  hill1 <- hill1$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill1[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate shannon diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsHAAQDGCS %>% filter(Order.q == 1) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
ShanEstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(ShanEstCor, method="circle")

# largest correlation
ind<-which(ShanEstCor==max(ShanEstCor),arr.ind = TRUE)
rownames(ShanEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.45) for unstructured data
hill1_map_HAA_QDGCU45 <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.45, data_type = "incidence") 
plot(hill1_map_HAA_QDGCU45, title = "Shannon diversity - unstructured data (0.45 coverage)")
```

Compare estimates

```{r}
hill1_map_HAA_QDGCU45$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot shannon diversity from unstructured data (b3gbi - coverage 0.45) and shannon diversity from iNEXT (0.995) from structured data
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCU45$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon diversity - structured data (iNEXT - 0.995)",
       y = "Shannon diversity - unstructured (b3gbi - 0.45)")
```

# Hill-Simpson Diversity (only possible for QDGC) - based on incidence data (structured and unstructured)

Unstructured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_HAA_QDGCU <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill2_map_HAA_QDGCU, title = "Simpson Diversity - unstructured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi and assume_freq = F

```{r}
# with default settings (coverage 0.95)
hill2_map_HAA_QDGCS <- hill2_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence") 
plot(hill2_map_HAA_QDGCS, title = "Simpson Diversity - structured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi and assume_frq = T

```{r}
# with default settings (coverage 0.95)
hill2_map_HAA_QDGCSas <- hill2_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence", assume_freq = T) 
plot(hill2_map_HAA_QDGCSas, title = "Simpson Diversity - structured data (0.95 coverage)")
```


Structured QDGC - calculated with iNEXT (i.e., actual survey effort used)

```{r}
hill2EstsHAAQDGCS<-inEXTestsHAAQDGCS %>% filter(Order.q == 2)
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill2_map_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill2_map_HAA_QDGCU$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_HAA_QDGCS$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_HAA_QDGCSas$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Simpson Diversity for structured data estimated uising b3gbi and Simpson Diversity from iNEXT for structured data (assume_freq for b3gbi = F)
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCS$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.995)",
       y = "Simpson Diversity - structured data (b3gbi -0.95)")
```

```{r}
# Plot Simpson Diversity for structured data estimated uising b3gbi and Simpson Diversity from iNEXT for structured data (assume_freq for b3gbi = T)
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCSas$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.995)",
       y = "Simpson Diversity - structured data (b3gbi -0.95)")
```


```{r}
# Plot Simpson Diversity for unstructured data estimated using b3gbi and Simpson Diversity from iNEXT from structured data
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCU$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT - 0.995)",
       y = "Simpson Diversity - unstructured data (b3gbi - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill2_map_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate simpson diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill2 <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "incidence",  coverage = i)
  hill2 <- hill2$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill2[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate simpson diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsHAAQDGCS %>% filter(Order.q == 2) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
SimpEstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(SimpEstCor, method="circle")

# largest correlation
ind<-which(SimpEstCor==max(SimpEstCor),arr.ind = TRUE)
rownames(SimpEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.45) for unstructured data
hill2_map_HAA_QDGCU45 <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.45, data_type = "incidence") 
plot(hill2_map_HAA_QDGCU45, title = "Simpson diversity - unstructured data (0.45 coverage)")
```

Compare estimates

```{r}
hill2_map_HAA_QDGCU45$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot simpson diversity from unstructured data (b3gbi - coverage 0.45) and simpson diversity from iNEXT (0.995) from structured data
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCU45$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson diversity - structured data (iNEXT - 0.995)",
       y = "Simpson diversity - unstructured data (b3gbi - 0.45)")
```

### Estimated richness - based on incidence data (structured) abundance data (unstructured)

Unstructured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_HAA_QDGCUAb <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("abundance")) 
plot(hill0_map_HAA_QDGCUAb, title = "Estimated Bird Species Richness - unstructured data (0.95 coverage)")
```

Structured QDGC - b3gbi with default settings

```{r}
# with default settings (coverage 0.95)
hill0_map_HAA_QDGCSAb <- hill0_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = c("abundance")) 
plot(hill0_map_HAA_QDGCSAb, title = "Estimated Bird Species Richness - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(map_obs_rich_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill0_map_HAA_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill0_map_HAA_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```


```{r}
# Plot estimated richness for structured data (b3gbi - coverage 0.95 using abundance) and estimated richness from iNEXT for structured data using incidence
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT - 0.995 - incidence)",
       y = "Estimated richness - structured data (b3gbi - 0.95 - abundance)")
```

```{r}
# Plot estimated richness for unstructured data (b3gbi - coverage 0.95, abundance) and estimated richness from iNEXT for structured data (incidence)
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT (incidence) - 0.995)",
       y = "Estimated richness - unstructured data (b3gbi(abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- map_obs_rich_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate richness for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill0 <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium",  coverage = i, data_type = "abundance") 
  hill0 <- hill0$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill0[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate richness for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-richEstsHAAQDGCS %>% filter(Order.q == 0) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
EstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(EstCor, method="circle")

# largest correlation
ind<-which(EstCor==max(EstCor),arr.ind = TRUE)
rownames(EstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.55) for unstructured data
hill0_map_HAA_QDGCU55Ab <- hill0_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.55, data_type = "abundance") 
plot(hill0_map_HAA_QDGCU55Ab, title = "Estimated Bird Species Richness - unstructured data (0.55 coverage)")
```

Compare estimates

```{r}
hill0_map_HAA_QDGCU55Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot estimated richness for unstructured data (b3gbi (abundance) - coverage 0.55) and estimated richness from iNEXT (incidence - 0.995 ) from structured data
richEstsHAAQDGCS %>% 
   inner_join(hill0_map_HAA_QDGCU55Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Estimated richness - structured data (iNEXT (incidence) - 0.995)",
       y = "Estimated richness - unstructured data (b3gbi (abundance) - 0.55)")
```

# Hill-Shannon Diversity (only possible for QDGC) - based on incidence (structured) and abundance (unstructured)

Unstructured data for QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill1_map_HAA_QDGCUAb <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill1_map_HAA_QDGCUAb, title = "Shannon Diversity - unstructured data (0.95 coverage)")
```

Structured data for QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill1_map_HAA_QDGCSAb <- hill1_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill1_map_HAA_QDGCSAb, title = "Shannon Diversity - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill1_map_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill1_map_HAA_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill1_map_HAA_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Shannon Diversity for structured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT - 0.995)",
       y = "Shannon Diversity - structured data (b3gbi - 0.95)")
```


```{r}
# Plot Shannon Diversity for unstructured data estimated using b3gbi and Shannon Diversity from iNEXT from structured data
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon Diversity - structured data (iNEXT (incidence) - 0.995)",
       y = "Shannon Diversity - unstructured data (b3gbi (abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill1_map_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate shannon diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill1 <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance",  coverage = i)
  hill1 <- hill1$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill1[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate shannon diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsHAAQDGCS %>% filter(Order.q == 1) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
ShanEstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(ShanEstCor, method="circle")

# largest correlation
ind<-which(ShanEstCor==max(ShanEstCor),arr.ind = TRUE)
rownames(ShanEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.15) for unstructured data
hill1_map_HAA_QDGCU15Ab <- hill1_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.15, data_type = "abundance") 
plot(hill1_map_HAA_QDGCU15Ab, title = "Shannon diversity - unstructured data (0.15 coverage)")
```

Compare estimates

```{r}
hill1_map_HAA_QDGCU15Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot shannon diversity from unstructured data (b3gbi (abundance) - coverage 0.15) and shannon diversity from iNEXT (incidence - 0.995) from structured data
hill1EstsHAAQDGCS %>% 
   inner_join(hill1_map_HAA_QDGCU15Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Shannon diversity - structured data (iNEXT (incidence) - 0.995)",
       y = "Shannon diversity - unstructured (b3gbi (abundance) - 0.15)")
```

# Hill-Simpson Diversity (only possible for QDGC) - based on incidence (structured) and abundance (unstructured)

Unstructured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_HAA_QDGCUAb <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill2_map_HAA_QDGCUAb, title = "Simpson Diversity - unstructured data (0.95 coverage)")
```

Structured QDGC - with default settings using b3gbi

```{r}
# with default settings (coverage 0.95)
hill2_map_HAA_QDGCSAb <- hill2_map(HAAStrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance") 
plot(hill2_map_HAA_QDGCSAb, title = "Simpson Diversity - structured data (0.95 coverage)")
```

Compare estimates

```{r}
# get qdgc codes for the b3gbi estimates
centroids <- st_centroid(hill2_map_HAA_QDGCU$data)
Hillcoords<-st_coordinates(centroids)

hill2_map_HAA_QDGCUAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))

hill2_map_HAA_QDGCSAb$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot Simpson Diversity for structured data estimated using b3gbi (abundance) and Simpson Diversity from iNEXT for structured data (incidence)
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCSAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT (incidence) - 0.995)",
       y = "Simpson Diversity - structured data (b3gbi (abundance) -0.95)")
```


```{r}
# Plot Simpson Diversity for unstructured data estimated using b3gbi (aundance) and Simpson Diversity from iNEXT from structured data (incidence)
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCUAb$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson Diversity - structured data (iNEXT (incidence) - 0.995)",
       y = "Simpson Diversity - unstructured data (b3gbi (abundance) - 0.95)")
```

Calculate estimates for unstructured data at different coverage thresholds and compare

```{r}
# Get qdgc codes
Codes<- hill2_map_HAA_QDGCU$data %>% select(QDGCcode) %>% st_drop_geometry()

# identify coverage levels for estimates
cov<-seq(0.05, 0.95, by = 0.1)

# loop to estimate simpson diversity for unstructured data using b3gbi at various coverage levels
UnstrucEsts<-Codes
for (i in cov){
  hill2 <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", data_type = "abundance",  coverage = i)
  hill2 <- hill2$data %>% st_drop_geometry()
  UnstrucEsts<-cbind(UnstrucEsts, hill2[,'diversity_val'])
  names(UnstrucEsts)[ncol(UnstrucEsts)]<-i
}

# Estimate simpson diversity for structured data using iNEXT 
StrucEsts<-Codes
iNEXTests<-inEXTestsHAAQDGCS %>% filter(Order.q == 2) %>% select(Assemblage, qD)
StrucEsts<-StrucEsts %>% left_join(iNEXTests, by = join_by(QDGCcode == Assemblage))

StrucEsts<-na.omit(StrucEsts) # remove rows with na
UnstrucEsts<-na.omit(UnstrucEsts) # remove rows with na

# correlation matrix
SimpEstCor<-cor(UnstrucEsts[2:ncol(UnstrucEsts)], StrucEsts[2], method = "pearson")

# plot correlation
corrplot(SimpEstCor, method="circle")

# largest correlation
ind<-which(SimpEstCor==max(SimpEstCor),arr.ind = TRUE)
rownames(SimpEstCor)[ind[, 1]]
```

Re-run and plot the best options

```{r}
# Estimates from b3gbi (coverage 0.05) for unstructured data
hill2_map_HAA_QDGCU05Ab <- hill2_map(HAAunstrucQDGCproc, cell_size = 0.25, level = "cube", region = "South Africa", ne_scale = "medium", coverage = 0.05, data_type = "abundance") 
plot(hill2_map_HAA_QDGCU05Ab, title = "Simpson diversity - unstructured data (0.05 coverage)")
```

Compare estimates

```{r}
hill2_map_HAA_QDGCU05Ab$data$QDGCcode<-apply(Hillcoords[,c('Y','X')], 1, function(y) get_qdgcCode(y['Y'],y['X']))
```

```{r}
# Plot simpson diversity from unstructured data (b3gbi (abundance) - coverage 0.05) and simpson diversity from iNEXT (incidence - 0.995) from structured data
hill2EstsHAAQDGCS %>% 
   inner_join(hill2_map_HAA_QDGCU05Ab$data,
            by = join_by(Assemblage == QDGCcode)) %>%
  ggplot(aes(x = qD, y = diversity_val)) +
  geom_point(color = "#66A61E") +
  ggpubr::stat_cor(mapping = aes(color = NULL),
           label.x.npc = "centre",
           label.y.npc = "bottom",
           method = "pearson") + labs(x = "Simpson diversity - structured data (iNEXT (incidence) - 0.995)",
       y = "Simpson diversity - unstructured data (b3gbi (abundance) - 0.05)")
```